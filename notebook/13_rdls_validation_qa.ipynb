{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 13: RDLS Validation and Quality Assurance\n",
    "\n",
    "**Purpose**: Validate integrated RDLS records (from Notebook 12) against the v0.3 JSON schema, score composite confidence, and produce tiered output packages.\n",
    "\n",
    "**Process**:\n",
    "1. Load all integrated RDLS records from `rdls/integrated/`\n",
    "2. Validate against RDLS v0.3 JSON schema\n",
    "3. Check HEVL block completeness and structure\n",
    "4. Compute composite confidence score per record\n",
    "5. Sort records into 3 confidence tiers: `high/`, `medium/`, `low/`\n",
    "6. Generate manifests, reports, and ZIP archive\n",
    "\n",
    "**Confidence Tiers**:\n",
    "- **`high/`** (score >= 0.8): Production-ready records. Have HEVL JSON blocks with high extraction confidence and pass schema validation.\n",
    "- **`medium/`** (0.5 <= score < 0.8): Review-needed records. May have partial HEVL blocks, lower confidence, or minor validation issues.\n",
    "- **`low/`** (score < 0.5): Curation-needed records. Flags-only (no HEVL JSON blocks), low confidence, or validation failures.\n",
    "\n",
    "**Author**: Benny Istanto/Risk Data Librarian/GFDRR  \n",
    "**Version**: 2026.2\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook started: 2026-02-11T18:29:45.906586\n",
      "JSON Schema validation: Available\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1.1 Import Dependencies\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import re\n",
    "import shutil\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import jsonschema\n",
    "    from jsonschema import Draft202012Validator, ValidationError\n",
    "    HAS_JSONSCHEMA = True\n",
    "except ImportError:\n",
    "    try:\n",
    "        from jsonschema import Draft7Validator as Draft202012Validator, ValidationError\n",
    "        HAS_JSONSCHEMA = True\n",
    "        print(\"Note: Draft202012Validator not available, falling back to Draft7Validator\")\n",
    "    except ImportError:\n",
    "        HAS_JSONSCHEMA = False\n",
    "        print(\"Warning: jsonschema not installed. Install with: pip install jsonschema\")\n",
    "\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "    HAS_TQDM = True\n",
    "except ImportError:\n",
    "    HAS_TQDM = False\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "print(f\"Notebook started: {datetime.now().isoformat()}\")\n",
    "print(f\"JSON Schema validation: {'Available' if HAS_JSONSCHEMA else 'Not available'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed stale: /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/dist/invalid\n",
      "Removed stale: /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/rdls_hdx_package_20260211.zip\n",
      "\n",
      "Base: /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler\n",
      "Integrated: /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/integrated\n",
      "Reports: /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/reports\n",
      "Dist: /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/dist\n",
      "  high/            (valid, score >= 0.8)\n",
      "  medium/          (valid, 0.5 <= score < 0.8)\n",
      "  low/             (valid, score < 0.5)\n",
      "  invalid/high/    (invalid, score >= 0.8)\n",
      "  invalid/medium/  (invalid, 0.5 <= score < 0.8)\n",
      "  invalid/low/     (invalid, score < 0.5)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1.2 Configure Paths\n",
    "\"\"\"\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "BASE_DIR = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == 'notebook' else NOTEBOOK_DIR\n",
    "\n",
    "# RDLS schema\n",
    "RDLS_SCHEMA_PATH = BASE_DIR / 'hdx_dataset_metadata_dump' / 'rdls' / 'schema' / 'rdls_schema_v0.3.json'\n",
    "\n",
    "# Input: integrated records from NB 12 only\n",
    "INTEGRATED_DIR = BASE_DIR / 'hdx_dataset_metadata_dump' / 'rdls' / 'integrated'\n",
    "\n",
    "# Output: reports and tiered dist\n",
    "REPORTS_DIR = BASE_DIR / 'hdx_dataset_metadata_dump' / 'rdls' / 'reports'\n",
    "DIST_DIR = BASE_DIR / 'hdx_dataset_metadata_dump' / 'rdls' / 'dist'\n",
    "\n",
    "# Confidence tier folders (under dist/) -- schema-VALID records only\n",
    "TIER_HIGH_DIR = DIST_DIR / 'high'\n",
    "TIER_MEDIUM_DIR = DIST_DIR / 'medium'\n",
    "TIER_LOW_DIR = DIST_DIR / 'low'\n",
    "\n",
    "# Invalid tier folders (schema-INVALID records, sub-tiered by confidence)\n",
    "INVALID_DIR = DIST_DIR / 'invalid'\n",
    "INVALID_HIGH_DIR = INVALID_DIR / 'high'\n",
    "INVALID_MEDIUM_DIR = INVALID_DIR / 'medium'\n",
    "INVALID_LOW_DIR = INVALID_DIR / 'low'\n",
    "\n",
    "# Confidence thresholds\n",
    "THRESHOLD_HIGH = 0.8\n",
    "THRESHOLD_MEDIUM = 0.5\n",
    "\n",
    "# Remove old flat 'records/' folder and stale files\n",
    "stale_records_dir = DIST_DIR / 'records'\n",
    "if stale_records_dir.exists():\n",
    "    shutil.rmtree(stale_records_dir)\n",
    "    print(f\"Removed stale: {stale_records_dir}\")\n",
    "\n",
    "for stale_file in ['rdls_index.csv', 'rdls_index.jsonl', 'rdls_metadata_bundle.zip']:\n",
    "    stale_path = DIST_DIR / stale_file\n",
    "    if stale_path.exists():\n",
    "        stale_path.unlink()\n",
    "        print(f\"Removed stale: {stale_path}\")\n",
    "\n",
    "# Remove old invalid/ tree from previous runs\n",
    "if INVALID_DIR.exists():\n",
    "    shutil.rmtree(INVALID_DIR)\n",
    "    print(f\"Removed stale: {INVALID_DIR}\")\n",
    "\n",
    "# Also remove old ZIP archives from parent dir\n",
    "for old_zip in (DIST_DIR.parent).glob('rdls_hdx_package_*.zip'):\n",
    "    old_zip.unlink()\n",
    "    print(f\"Removed stale: {old_zip}\")\n",
    "\n",
    "# Create fresh directories\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DIST_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TIER_HIGH_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TIER_MEDIUM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TIER_LOW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "INVALID_HIGH_DIR.mkdir(parents=True, exist_ok=True)\n",
    "INVALID_MEDIUM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "INVALID_LOW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nBase: {BASE_DIR}\")\n",
    "print(f\"Integrated: {INTEGRATED_DIR}\")\n",
    "print(f\"Reports: {REPORTS_DIR}\")\n",
    "print(f\"Dist: {DIST_DIR}\")\n",
    "print(f\"  high/            (valid, score >= {THRESHOLD_HIGH})\")\n",
    "print(f\"  medium/          (valid, {THRESHOLD_MEDIUM} <= score < {THRESHOLD_HIGH})\")\n",
    "print(f\"  low/             (valid, score < {THRESHOLD_MEDIUM})\")\n",
    "print(f\"  invalid/high/    (invalid, score >= {THRESHOLD_HIGH})\")\n",
    "print(f\"  invalid/medium/  (invalid, {THRESHOLD_MEDIUM} <= score < {THRESHOLD_HIGH})\")\n",
    "print(f\"  invalid/low/     (invalid, score < {THRESHOLD_MEDIUM})\")\n",
    "\n",
    "\n",
    "CLEANUP_MODE = \"replace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output cleanup [NB 13 high]:\n",
      "  *.json                                  : 9,797 files\n",
      "  manifest.csv                            : 1 files\n",
      "  Cleaned 9,798 files. Ready for fresh output.\n",
      "\n",
      "Output cleanup [NB 13 medium]:\n",
      "  manifest.csv                            : 1 files\n",
      "  Cleaned 1 files. Ready for fresh output.\n",
      "\n",
      "Output cleanup [NB 13 low]:\n",
      "  manifest.csv                            : 1 files\n",
      "  Cleaned 1 files. Ready for fresh output.\n",
      "\n",
      "Output cleanup [NB 13 invalid/high]: Directory is clean.\n",
      "Output cleanup [NB 13 invalid/medium]: Directory is clean.\n",
      "Output cleanup [NB 13 invalid/low]: Directory is clean.\n",
      "Output cleanup [NB 13 Reports]:\n",
      "  *.csv                                   : 6 files\n",
      "  *.md                                    : 1 files\n",
      "  Cleaned 7 files. Ready for fresh output.\n",
      "\n",
      "Output cleanup [NB 13 Dist Files]:\n",
      "  master_manifest.csv                     : 1 files\n",
      "  README.md                               : 1 files\n",
      "  Cleaned 2 files. Ready for fresh output.\n",
      "\n",
      "Output cleanup [NB 13 ZIP Archives]: Directory is clean.\n",
      "Removed stale: /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/dist/invalid\n",
      "Output directories ready.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1.3 Clean Previous Outputs\n",
    "\n",
    "Remove stale output files from previous runs (controlled by CLEANUP_MODE).\n",
    "\"\"\"\n",
    "import shutil\n",
    "\n",
    "def clean_previous_outputs(output_dir, patterns, label, mode=\"replace\"):\n",
    "    \"\"\"\n",
    "    Remove previous output files matching the given glob patterns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    output_dir : Path\n",
    "        Directory containing old outputs.\n",
    "    patterns : list[str]\n",
    "        Glob patterns to match.\n",
    "    label : str\n",
    "        Human-readable label for log messages.\n",
    "    mode : str\n",
    "        One of: \"replace\" (auto-delete), \"prompt\" (ask user),\n",
    "        \"skip\" (keep old files), \"abort\" (error if stale files exist).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict  with keys 'deleted' (int) and 'skipped' (bool)\n",
    "    \"\"\"\n",
    "    result = {'deleted': 0, 'skipped': False}\n",
    "    targets = {}\n",
    "    for pattern in patterns:\n",
    "        matches = sorted(output_dir.glob(pattern))\n",
    "        if matches:\n",
    "            targets[pattern] = matches\n",
    "    total = sum(len(files) for files in targets.values())\n",
    "\n",
    "    if total == 0:\n",
    "        print(f'Output cleanup [{label}]: Directory is clean.')\n",
    "        return result\n",
    "\n",
    "    summary = []\n",
    "    for pattern, files in targets.items():\n",
    "        summary.append(f'  {pattern:40s}: {len(files):,} files')\n",
    "\n",
    "    if mode == 'skip':\n",
    "        print(f'Output cleanup [{label}]: SKIPPED ({total:,} existing files kept)')\n",
    "        result['skipped'] = True\n",
    "        return result\n",
    "\n",
    "    if mode == 'abort':\n",
    "        raise RuntimeError(\n",
    "            f'Output cleanup [{label}]: ABORT -- {total:,} stale files found. '\n",
    "            f'Delete manually or change CLEANUP_MODE.'\n",
    "        )\n",
    "\n",
    "    if mode == 'prompt':\n",
    "        print(f'Output cleanup [{label}]: Found {total:,} existing output files:')\n",
    "        for line in summary:\n",
    "            print(line)\n",
    "        choice = input('Choose [R]eplace / [S]kip / [A]bort: ').strip().lower()\n",
    "        if choice in ('s', 'skip'):\n",
    "            print('  Skipped.')\n",
    "            result['skipped'] = True\n",
    "            return result\n",
    "        elif choice in ('a', 'abort'):\n",
    "            raise RuntimeError('User chose to abort.')\n",
    "        elif choice not in ('r', 'replace', ''):\n",
    "            print(f'  Unknown choice, defaulting to Replace.')\n",
    "\n",
    "    # Mode: replace (default)\n",
    "    print(f'Output cleanup [{label}]:')\n",
    "    for line in summary:\n",
    "        print(line)\n",
    "    for pattern, files in targets.items():\n",
    "        for f in files:\n",
    "            try:\n",
    "                f.unlink()\n",
    "                result['deleted'] += 1\n",
    "            except Exception as e:\n",
    "                print(f'  WARNING: Could not delete {f.name}: {e}')\n",
    "    deleted_count = result['deleted']\n",
    "    print(f'  Cleaned {deleted_count:,} files. Ready for fresh output.')\n",
    "    print()\n",
    "    return result\n",
    "\n",
    "# ── Run cleanup ────────────────────────────────────────────────────────\n",
    "# Clean tier directories (valid + invalid)\n",
    "for tier_dir in [TIER_HIGH_DIR, TIER_MEDIUM_DIR, TIER_LOW_DIR,\n",
    "                 INVALID_HIGH_DIR, INVALID_MEDIUM_DIR, INVALID_LOW_DIR]:\n",
    "    if tier_dir.exists():\n",
    "        clean_previous_outputs(\n",
    "            tier_dir,\n",
    "            patterns=[\"*.json\", \"manifest.csv\"],\n",
    "            label=f\"NB 13 {tier_dir.relative_to(DIST_DIR)}\",\n",
    "            mode=CLEANUP_MODE,\n",
    "        )\n",
    "\n",
    "# Clean reports\n",
    "clean_previous_outputs(\n",
    "    REPORTS_DIR,\n",
    "    patterns=[\"*.csv\", \"*.md\", \"*.json\"],\n",
    "    label=\"NB 13 Reports\",\n",
    "    mode=CLEANUP_MODE,\n",
    ")\n",
    "\n",
    "# Clean dist-level files\n",
    "clean_previous_outputs(\n",
    "    DIST_DIR,\n",
    "    patterns=[\"master_manifest.csv\", \"README.md\"],\n",
    "    label=\"NB 13 Dist Files\",\n",
    "    mode=CLEANUP_MODE,\n",
    ")\n",
    "\n",
    "# Clean ZIP archives\n",
    "clean_previous_outputs(\n",
    "    DIST_DIR.parent,\n",
    "    patterns=[\"rdls_hdx_package_*.zip\"],\n",
    "    label=\"NB 13 ZIP Archives\",\n",
    "    mode=CLEANUP_MODE,\n",
    ")\n",
    "\n",
    "# Remove stale invalid/ tree and recreate\n",
    "if INVALID_DIR.exists() and CLEANUP_MODE == \"replace\":\n",
    "    shutil.rmtree(INVALID_DIR)\n",
    "    print(f\"Removed stale: {INVALID_DIR}\")\n",
    "\n",
    "# Ensure all output directories exist\n",
    "for d in [TIER_HIGH_DIR, TIER_MEDIUM_DIR, TIER_LOW_DIR,\n",
    "          INVALID_HIGH_DIR, INVALID_MEDIUM_DIR, INVALID_LOW_DIR,\n",
    "          REPORTS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Output directories ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDLS Schema loaded: https://docs.riskdatalibrary.org/en/0__3__0/rdls_schema.json\n",
      "Schema draft: https://json-schema.org/draft/2020-12/schema\n",
      "Required top-level fields: ['id', 'title', 'risk_data_type', 'attributions', 'spatial', 'license', 'resources']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1.3 Load RDLS Schema\n",
    "\"\"\"\n",
    "\n",
    "with open(RDLS_SCHEMA_PATH, 'r', encoding='utf-8') as f:\n",
    "    RDLS_SCHEMA = json.load(f)\n",
    "\n",
    "print(f\"RDLS Schema loaded: {RDLS_SCHEMA.get('$id', 'unknown')}\")\n",
    "print(f\"Schema draft: {RDLS_SCHEMA.get('$schema', 'unknown')}\")\n",
    "print(f\"Required top-level fields: {RDLS_SCHEMA.get('required', [])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load RDLS Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12577 RDLS files in integrated/\n",
      "  Loaded: 12577\n",
      "  Load errors: 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "2.1 Find and Load Integrated RDLS Records\n",
    "\n",
    "Only load from integrated/ directory (NB 12 output).\n",
    "Do NOT mix with extracted/ samples to avoid duplicates.\n",
    "\"\"\"\n",
    "\n",
    "def load_rdls_records(directory: Path) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Load all RDLS JSON files from directory.\"\"\"\n",
    "    records = []\n",
    "    \n",
    "    for filepath in sorted(directory.glob('rdls_*.json')):\n",
    "        entry = {\n",
    "            'filepath': filepath,\n",
    "            'filename': filepath.name,\n",
    "        }\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                entry['data'] = json.load(f)\n",
    "        except Exception as e:\n",
    "            entry['load_error'] = str(e)\n",
    "        \n",
    "        records.append(entry)\n",
    "    \n",
    "    return records\n",
    "\n",
    "rdls_records = load_rdls_records(INTEGRATED_DIR)\n",
    "loaded = sum(1 for r in rdls_records if 'data' in r)\n",
    "errors = sum(1 for r in rdls_records if 'load_error' in r)\n",
    "\n",
    "print(f\"Found {len(rdls_records)} RDLS files in {INTEGRATED_DIR.name}/\")\n",
    "print(f\"  Loaded: {loaded}\")\n",
    "print(f\"  Load errors: {errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample record: rdls_exp-hdx_3is_col_calculo_de_personas_en_necesidad_pin_del_cluster.json\n",
      "  id: rdls_exp-hdx_3is_col_calculo_de_personas_en_necesidad_pin_del_cluster\n",
      "  title: Colombia: Cálculo de Personas en Necesidad (PiN) del Clúster de Agua, Saneamient\n",
      "  risk_data_type: ['exposure']\n",
      "  Top-level keys: ['id', 'title', 'description', 'risk_data_type', 'details', 'spatial', 'license', 'attributions', 'resources', 'exposure', 'links']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "2.2 Quick Data Preview\n",
    "\"\"\"\n",
    "\n",
    "if rdls_records and 'data' in rdls_records[0]:\n",
    "    sample = rdls_records[0]['data']['datasets'][0]\n",
    "    print(f\"Sample record: {rdls_records[0]['filename']}\")\n",
    "    print(f\"  id: {sample.get('id', '')}\")\n",
    "    print(f\"  title: {(sample.get('title', '') or '')[:80]}\")\n",
    "    print(f\"  risk_data_type: {sample.get('risk_data_type', [])}\")\n",
    "    print(f\"  Top-level keys: {list(sample.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Schema Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema validator defined.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "3.1 Schema Validator\n",
    "\n",
    "The RDLS v0.3 schema root validates a single Dataset object.\n",
    "Our files wrap datasets in {\"datasets\": [...]}, so we validate datasets[0].\n",
    "\n",
    "Schema uses draft/2020-12; we try Draft202012Validator first,\n",
    "falling back to Draft7Validator if the newer one isn't available.\n",
    "\"\"\"\n",
    "\n",
    "def validate_rdls_record(dataset: Dict[str, Any], schema: Dict[str, Any]) -> Tuple[bool, List[str]]:\n",
    "    \"\"\"\n",
    "    Validate a single RDLS dataset object against the schema.\n",
    "    \n",
    "    Returns (is_valid, error_messages).\n",
    "    \"\"\"\n",
    "    if not HAS_JSONSCHEMA:\n",
    "        return True, ['Schema validation skipped (jsonschema not installed)']\n",
    "    \n",
    "    errors = []\n",
    "    try:\n",
    "        validator = Draft202012Validator(schema)\n",
    "        for error in validator.iter_errors(dataset):\n",
    "            path = '/'.join(str(p) for p in error.absolute_path)\n",
    "            msg = f\"{path}: {error.message}\" if path else error.message\n",
    "            errors.append(msg)\n",
    "    except Exception as e:\n",
    "        errors.append(f\"Validation exception: {e}\")\n",
    "    \n",
    "    return len(errors) == 0, errors\n",
    "\n",
    "print(\"Schema validator defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0b7d01089345d3acc3f71f7560c065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/12577 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SCHEMA VALIDATION RESULTS\n",
      "============================================================\n",
      "Total records:  12577\n",
      "Valid:          9797 (77.9%)\n",
      "Invalid:        2780 (22.1%)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "3.2 Run Schema Validation\n",
    "\"\"\"\n",
    "\n",
    "validation_results = []\n",
    "\n",
    "iterator = tqdm(rdls_records, desc=\"Validating\") if HAS_TQDM else rdls_records\n",
    "\n",
    "for record in iterator:\n",
    "    result = {\n",
    "        'filename': record['filename'],\n",
    "        'filepath': str(record['filepath']),\n",
    "    }\n",
    "    \n",
    "    if 'load_error' in record:\n",
    "        result['status'] = 'load_error'\n",
    "        result['errors'] = [record['load_error']]\n",
    "        result['error_count'] = 1\n",
    "    else:\n",
    "        data = record['data']\n",
    "        # Extract dataset object from wrapper\n",
    "        if 'datasets' in data and data['datasets']:\n",
    "            dataset = data['datasets'][0]\n",
    "        else:\n",
    "            dataset = data\n",
    "        \n",
    "        is_valid, errors = validate_rdls_record(dataset, RDLS_SCHEMA)\n",
    "        result['status'] = 'valid' if is_valid else 'invalid'\n",
    "        result['errors'] = errors\n",
    "        result['error_count'] = len(errors)\n",
    "        result['id'] = dataset.get('id', '')\n",
    "        result['title'] = (dataset.get('title', '') or '')[:80]\n",
    "        result['risk_data_type'] = '|'.join(dataset.get('risk_data_type', []))\n",
    "    \n",
    "    validation_results.append(result)\n",
    "\n",
    "df_validation = pd.DataFrame(validation_results)\n",
    "\n",
    "valid_count = (df_validation['status'] == 'valid').sum()\n",
    "invalid_count = (df_validation['status'] == 'invalid').sum()\n",
    "total_count = len(df_validation)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SCHEMA VALIDATION RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total records:  {total_count}\")\n",
    "print(f\"Valid:          {valid_count} ({valid_count/total_count*100:.1f}%)\" if total_count else \"\")\n",
    "print(f\"Invalid:        {invalid_count} ({invalid_count/total_count*100:.1f}%)\" if total_count else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VALIDATION ERRORS (2780 records, 3184 total errors)\n",
      "============================================================\n",
      "\n",
      "Error Categories:\n",
      "  Missing required fields:  0\n",
      "  Invalid enum values:      6\n",
      "  Type errors:              0\n",
      "  AnyOf constraint failures:0\n",
      "  Other errors:             3178\n",
      "\n",
      "Top 20 errors:\n",
      "  [2774] hazard/event_sets/0/events/0/occurrence: {} should be non-empty\n",
      "  [ 366] hazard/event_sets/1/events/0/occurrence: {} should be non-empty\n",
      "  [  34] hazard/event_sets/2/events/0/occurrence: {} should be non-empty\n",
      "  [   4] spatial/countries/0: 'XKX' is not one of ['AFG', 'ALB', 'DZA', 'ASM', 'AND', 'AGO', 'AIA', 'ATA', 'ATG', 'ARG', 'ARM', '...\n",
      "  [   3] hazard/event_sets/3/events/0/occurrence: {} should be non-empty\n",
      "  [   1] spatial/countries/203: 'XKX' is not one of ['AFG', 'ALB', 'DZA', 'ASM', 'AND', 'AGO', 'AIA', 'ATA', 'ATG', 'ARG', 'ARM',...\n",
      "  [   1] spatial/countries/137: 'XKX' is not one of ['AFG', 'ALB', 'DZA', 'ASM', 'AND', 'AGO', 'AIA', 'ATA', 'ATG', 'ARG', 'ARM',...\n",
      "  [   1] hazard/event_sets/4/events/0/occurrence: {} should be non-empty\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "3.3 Analyze Validation Errors\n",
    "\"\"\"\n",
    "\n",
    "invalid_records = df_validation[df_validation['status'] == 'invalid']\n",
    "\n",
    "if len(invalid_records) > 0:\n",
    "    # Collect all errors\n",
    "    all_errors = []\n",
    "    for errors in invalid_records['errors']:\n",
    "        if isinstance(errors, list):\n",
    "            all_errors.extend(errors)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"VALIDATION ERRORS ({len(invalid_records)} records, {len(all_errors)} total errors)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Categorize errors\n",
    "    missing_required = [e for e in all_errors if 'is a required property' in e]\n",
    "    invalid_enum = [e for e in all_errors if 'is not one of' in e or 'enum' in e.lower()]\n",
    "    invalid_type = [e for e in all_errors if 'is not of type' in e]\n",
    "    invalid_anyof = [e for e in all_errors if 'anyOf' in e or 'is not valid under any' in e]\n",
    "    other_errors = [e for e in all_errors \n",
    "                    if e not in missing_required + invalid_enum + invalid_type + invalid_anyof]\n",
    "    \n",
    "    print(f\"\\nError Categories:\")\n",
    "    print(f\"  Missing required fields:  {len(missing_required)}\")\n",
    "    print(f\"  Invalid enum values:      {len(invalid_enum)}\")\n",
    "    print(f\"  Type errors:              {len(invalid_type)}\")\n",
    "    print(f\"  AnyOf constraint failures:{len(invalid_anyof)}\")\n",
    "    print(f\"  Other errors:             {len(other_errors)}\")\n",
    "    \n",
    "    # Top 20 unique errors\n",
    "    error_counts = Counter(all_errors)\n",
    "    print(f\"\\nTop 20 errors:\")\n",
    "    for err, count in error_counts.most_common(20):\n",
    "        display = err[:120] + '...' if len(err) > 120 else err\n",
    "        print(f\"  [{count:>4}] {display}\")\n",
    "    \n",
    "    # Extract unique missing field names\n",
    "    if missing_required:\n",
    "        unique_missing = set()\n",
    "        for e in missing_required:\n",
    "            match = re.search(r\"'([^']+)' is a required property\", e)\n",
    "            if match:\n",
    "                unique_missing.add(match.group(1))\n",
    "        print(f\"\\n  Missing required fields: {sorted(unique_missing)}\")\n",
    "else:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ALL RECORDS PASSED SCHEMA VALIDATION!\")\n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. HEVL Completeness Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "HEVL BLOCK COMPLETENESS\n",
      "============================================================\n",
      "Records analyzed: 12577\n",
      "\n",
      "Block presence:\n",
      "  has_hazard               :   2788 ( 22.2%)\n",
      "  has_exposure             :  11517 ( 91.6%)\n",
      "  has_vulnerability        :   3429 ( 27.3%)\n",
      "  has_loss                 :    703 (  5.6%)\n",
      "\n",
      "HEVL blocks per record:\n",
      "  1 blocks:   7363 ( 58.5%)\n",
      "  2 blocks:   4599 ( 36.6%)\n",
      "  3 blocks:    584 (  4.6%)\n",
      "  4 blocks:     31 (  0.2%)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "4.1 Check HEVL Block Completeness\n",
    "\"\"\"\n",
    "\n",
    "def check_hevl_completeness(data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Check presence and structure of HEVL blocks in a record.\"\"\"\n",
    "    if 'datasets' not in data or not data['datasets']:\n",
    "        return {'error': 'No datasets array'}\n",
    "    \n",
    "    ds = data['datasets'][0]\n",
    "    result = {\n",
    "        'has_hazard': 'hazard' in ds,\n",
    "        'has_exposure': 'exposure' in ds,\n",
    "        'has_vulnerability': 'vulnerability' in ds,\n",
    "        'has_loss': 'loss' in ds,\n",
    "    }\n",
    "    \n",
    "    # Count how many HEVL components have actual blocks (not just risk_data_type flags)\n",
    "    result['hevl_block_count'] = sum([\n",
    "        result['has_hazard'],\n",
    "        result['has_exposure'],\n",
    "        result['has_vulnerability'],\n",
    "        result['has_loss'],\n",
    "    ])\n",
    "    \n",
    "    # Count declared risk_data_type components\n",
    "    risk_types = ds.get('risk_data_type', [])\n",
    "    result['declared_component_count'] = len(risk_types) if isinstance(risk_types, list) else 0\n",
    "    \n",
    "    # Hazard detail\n",
    "    if result['has_hazard']:\n",
    "        hazard = ds['hazard']\n",
    "        event_sets = hazard.get('event_sets', [])\n",
    "        result['hazard_event_sets'] = len(event_sets)\n",
    "        if event_sets:\n",
    "            es = event_sets[0]\n",
    "            result['hazard_analysis_type'] = es.get('analysis_type', '')\n",
    "            result['hazard_hazards_count'] = len(es.get('hazards', []))\n",
    "            result['hazard_events_count'] = len(es.get('events', []))\n",
    "            # Check if events have return periods (probabilistic)\n",
    "            result['hazard_has_return_periods'] = any(\n",
    "                ev.get('occurrence', {}).get('probabilistic', {}).get('return_period')\n",
    "                for ev in es.get('events', [])\n",
    "            )\n",
    "        else:\n",
    "            result['hazard_event_sets'] = 0\n",
    "    \n",
    "    # Exposure detail\n",
    "    if result['has_exposure']:\n",
    "        exposure = ds['exposure']\n",
    "        if isinstance(exposure, list):\n",
    "            result['exposure_items'] = len(exposure)\n",
    "            categories = [item.get('category', '') for item in exposure]\n",
    "            result['exposure_categories'] = '|'.join(categories)\n",
    "            # Check if metrics are populated\n",
    "            result['exposure_has_metrics'] = any(\n",
    "                item.get('metrics') for item in exposure\n",
    "            )\n",
    "        else:\n",
    "            result['exposure_items'] = 0\n",
    "            result['exposure_has_metrics'] = False\n",
    "    \n",
    "    # Vulnerability detail\n",
    "    if result['has_vulnerability']:\n",
    "        vuln = ds['vulnerability']\n",
    "        result['vuln_has_functions'] = bool(vuln.get('functions'))\n",
    "        socio = vuln.get('socio_economic', [])\n",
    "        result['vuln_socio_count'] = len(socio) if isinstance(socio, list) else 0\n",
    "    \n",
    "    # Loss detail\n",
    "    if result['has_loss']:\n",
    "        loss = ds['loss']\n",
    "        losses = loss.get('losses', [])\n",
    "        result['loss_items'] = len(losses)\n",
    "        if losses:\n",
    "            hazard_types = set(l.get('hazard_type', '') for l in losses)\n",
    "            result['loss_hazard_types'] = '|'.join(sorted(hazard_types - {''}))\n",
    "    \n",
    "    return result\n",
    "\n",
    "completeness_results = []\n",
    "for record in rdls_records:\n",
    "    if 'data' in record:\n",
    "        res = check_hevl_completeness(record['data'])\n",
    "        res['filename'] = record['filename']\n",
    "        completeness_results.append(res)\n",
    "\n",
    "df_completeness = pd.DataFrame(completeness_results)\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(\"HEVL BLOCK COMPLETENESS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Records analyzed: {len(df_completeness)}\")\n",
    "print(f\"\\nBlock presence:\")\n",
    "for col in ['has_hazard', 'has_exposure', 'has_vulnerability', 'has_loss']:\n",
    "    if col in df_completeness:\n",
    "        count = df_completeness[col].sum()\n",
    "        pct = count / len(df_completeness) * 100\n",
    "        print(f\"  {col:25s}: {count:>6} ({pct:>5.1f}%)\")\n",
    "\n",
    "# Block count distribution\n",
    "if 'hevl_block_count' in df_completeness:\n",
    "    print(f\"\\nHEVL blocks per record:\")\n",
    "    for n, count in df_completeness['hevl_block_count'].value_counts().sort_index().items():\n",
    "        pct = count / len(df_completeness) * 100\n",
    "        print(f\"  {n} blocks: {count:>6} ({pct:>5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "HAZARD BLOCK QUALITY (2788 records)\n",
      "============================================================\n",
      "\n",
      "Analysis types:\n",
      "hazard_analysis_type\n",
      "empirical        2744\n",
      "probabilistic      22\n",
      "deterministic      22\n",
      "\n",
      "Avg hazards per event_set: 1.0\n",
      "Records with events: 2788/2788\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "4.2 Hazard Block Quality\n",
    "\"\"\"\n",
    "\n",
    "hazard_records = df_completeness[df_completeness.get('has_hazard', pd.Series(dtype=bool)) == True]\n",
    "\n",
    "if len(hazard_records) > 0:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"HAZARD BLOCK QUALITY ({len(hazard_records)} records)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if 'hazard_analysis_type' in hazard_records:\n",
    "        print(f\"\\nAnalysis types:\")\n",
    "        print(hazard_records['hazard_analysis_type'].value_counts().to_string())\n",
    "    if 'hazard_hazards_count' in hazard_records:\n",
    "        print(f\"\\nAvg hazards per event_set: {hazard_records['hazard_hazards_count'].mean():.1f}\")\n",
    "    if 'hazard_events_count' in hazard_records:\n",
    "        with_events = (hazard_records['hazard_events_count'] > 0).sum()\n",
    "        print(f\"Records with events: {with_events}/{len(hazard_records)}\")\n",
    "else:\n",
    "    print(\"\\nNo hazard blocks found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Composite Confidence Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composite confidence scorer defined.\n",
      "Weights: HEVL coverage 40%, Block richness 25%, Schema 20%, Metadata 15%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "5.1 Compute Composite Confidence Score\n",
    "\n",
    "The composite score combines:\n",
    "1. HEVL block presence (do we have actual structured blocks, not just flags?)\n",
    "2. Block richness (how detailed are the blocks?)\n",
    "3. Schema validity (does the record pass validation?)\n",
    "4. General metadata quality (description, spatial, attributions populated?)\n",
    "\n",
    "Scoring weights:\n",
    "  - HEVL block coverage:    40%  (most important - actual data content)\n",
    "  - Block richness:         25%  (depth of HEVL detail)\n",
    "  - Schema validity:        20%  (structural compliance)\n",
    "  - Metadata completeness:  15%  (general metadata quality)\n",
    "\"\"\"\n",
    "\n",
    "def compute_composite_confidence(\n",
    "    record_data: Dict[str, Any],\n",
    "    completeness: Dict[str, Any],\n",
    "    validation_status: str,\n",
    "    validation_error_count: int,\n",
    ") -> Tuple[float, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Compute composite confidence score for a single RDLS record.\n",
    "    \n",
    "    Returns (composite_score, component_scores_dict)\n",
    "    \"\"\"\n",
    "    ds = record_data.get('datasets', [{}])[0]\n",
    "    risk_types = ds.get('risk_data_type', [])\n",
    "    declared_count = len(risk_types) if isinstance(risk_types, list) else 0\n",
    "    \n",
    "    # --- 1. HEVL Block Coverage (0-1) ---\n",
    "    # Ratio of actual HEVL blocks present vs. declared risk_data_types\n",
    "    block_count = completeness.get('hevl_block_count', 0)\n",
    "    if declared_count > 0:\n",
    "        hevl_coverage = min(block_count / declared_count, 1.0)\n",
    "    else:\n",
    "        hevl_coverage = 0.0\n",
    "    \n",
    "    # --- 2. Block Richness (0-1) ---\n",
    "    # How detailed/populated are the HEVL blocks?\n",
    "    richness_signals = []\n",
    "    \n",
    "    if completeness.get('has_hazard'):\n",
    "        h_score = 0.5  # base: block exists\n",
    "        if completeness.get('hazard_event_sets', 0) > 0:\n",
    "            h_score += 0.2\n",
    "        if completeness.get('hazard_events_count', 0) > 0:\n",
    "            h_score += 0.15\n",
    "        if completeness.get('hazard_has_return_periods', False):\n",
    "            h_score += 0.15\n",
    "        richness_signals.append(min(h_score, 1.0))\n",
    "    \n",
    "    if completeness.get('has_exposure'):\n",
    "        e_score = 0.5\n",
    "        if completeness.get('exposure_items', 0) > 0:\n",
    "            e_score += 0.25\n",
    "        if completeness.get('exposure_has_metrics', False):\n",
    "            e_score += 0.25\n",
    "        richness_signals.append(min(e_score, 1.0))\n",
    "    \n",
    "    if completeness.get('has_vulnerability'):\n",
    "        v_score = 0.5\n",
    "        if completeness.get('vuln_has_functions', False):\n",
    "            v_score += 0.25\n",
    "        if completeness.get('vuln_socio_count', 0) > 0:\n",
    "            v_score += 0.25\n",
    "        richness_signals.append(min(v_score, 1.0))\n",
    "    \n",
    "    if completeness.get('has_loss'):\n",
    "        l_score = 0.5\n",
    "        if completeness.get('loss_items', 0) > 0:\n",
    "            l_score += 0.3\n",
    "        if completeness.get('loss_hazard_types', ''):\n",
    "            l_score += 0.2\n",
    "        richness_signals.append(min(l_score, 1.0))\n",
    "    \n",
    "    block_richness = np.mean(richness_signals) if richness_signals else 0.0\n",
    "    \n",
    "    # --- 3. Schema Validity (0-1) ---\n",
    "    if validation_status == 'valid':\n",
    "        schema_score = 1.0\n",
    "    elif validation_error_count <= 2:\n",
    "        schema_score = 0.7  # Minor issues\n",
    "    elif validation_error_count <= 5:\n",
    "        schema_score = 0.4  # Moderate issues\n",
    "    else:\n",
    "        schema_score = 0.1  # Many issues\n",
    "    \n",
    "    # --- 4. Metadata Completeness (0-1) ---\n",
    "    meta_signals = []\n",
    "    # Description present and non-trivial\n",
    "    desc = ds.get('description', '') or ''\n",
    "    meta_signals.append(1.0 if len(desc) > 20 else 0.3)\n",
    "    # Spatial countries populated\n",
    "    countries = ds.get('spatial', {}).get('countries', [])\n",
    "    meta_signals.append(1.0 if countries else 0.3)\n",
    "    # Attributions have at least 3 roles\n",
    "    attributions = ds.get('attributions', [])\n",
    "    roles = set(a.get('role', '') for a in attributions)\n",
    "    required_roles = {'publisher', 'creator', 'contact_point'}\n",
    "    meta_signals.append(1.0 if required_roles.issubset(roles) else 0.5)\n",
    "    # Resources present with download URLs\n",
    "    resources = ds.get('resources', [])\n",
    "    has_download = any(r.get('download_url') or r.get('access_url') for r in resources)\n",
    "    meta_signals.append(1.0 if has_download else 0.3)\n",
    "    \n",
    "    metadata_score = np.mean(meta_signals)\n",
    "    \n",
    "    # --- Weighted Composite ---\n",
    "    composite = (\n",
    "        0.40 * hevl_coverage +\n",
    "        0.25 * block_richness +\n",
    "        0.20 * schema_score +\n",
    "        0.15 * metadata_score\n",
    "    )\n",
    "    \n",
    "    components = {\n",
    "        'hevl_coverage': round(hevl_coverage, 3),\n",
    "        'block_richness': round(block_richness, 3),\n",
    "        'schema_score': round(schema_score, 3),\n",
    "        'metadata_score': round(metadata_score, 3),\n",
    "    }\n",
    "    \n",
    "    return round(composite, 3), components\n",
    "\n",
    "print(\"Composite confidence scorer defined.\")\n",
    "print(\"Weights: HEVL coverage 40%, Block richness 25%, Schema 20%, Metadata 15%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Score All Records and Assign Tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22fd5b0bf73e4a45aaa43d79fb3b2d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring:   0%|          | 0/12577 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPOSITE CONFIDENCE SCORING\n",
      "============================================================\n",
      "Total records scored: 12,577\n",
      "\n",
      "Score distribution:\n",
      "  Mean:   0.973\n",
      "  Median: 0.974\n",
      "  Min:    0.816\n",
      "  Max:    1.000\n",
      "\n",
      "Tier distribution:\n",
      "  high    : 12,577 (100.0%)\n",
      "  medium  :      0 (  0.0%)\n",
      "  low     :      0 (  0.0%)\n",
      "\n",
      "Two-dimensional distribution (confidence x validity):\n",
      "  high    :  9,797 valid +  2,780 invalid = 12,577 total\n",
      "  medium  :      0 valid +      0 invalid =      0 total\n",
      "  low     :      0 valid +      0 invalid =      0 total\n",
      "\n",
      "Component score averages:\n",
      "  hevl_coverage       : 1.000\n",
      "  block_richness      : 0.946\n",
      "  schema_score        : 0.933\n",
      "  metadata_score      : 0.997\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "6.1 Compute Scores and Assign Confidence Tiers\n",
    "\"\"\"\n",
    "\n",
    "# Build lookup dicts for validation and completeness by filename\n",
    "def _summarize_errors(errors):\n",
    "    \"\"\"Categorize validation errors into a concise summary string.\"\"\"\n",
    "    if not errors or not isinstance(errors, list) or len(errors) == 0:\n",
    "        return ''\n",
    "    cats = {'missing_field': [], 'invalid_enum': [], 'type_error': [],\n",
    "            'anyOf': [], 'other': []}\n",
    "    for e in errors:\n",
    "        if 'is a required property' in e:\n",
    "            # Extract field name\n",
    "            import re as _re\n",
    "            m = _re.search(r\"'([^']+)' is a required property\", e)\n",
    "            field = m.group(1) if m else '?'\n",
    "            cats['missing_field'].append(field)\n",
    "        elif 'is not one of' in e or 'enum' in str(e).lower():\n",
    "            cats['invalid_enum'].append(e.split(':')[0] if ':' in e else e[:50])\n",
    "        elif 'is not of type' in e:\n",
    "            cats['type_error'].append(e.split(':')[0] if ':' in e else e[:50])\n",
    "        elif 'anyOf' in e or 'is not valid under any' in e:\n",
    "            cats['anyOf'].append(e.split(':')[0] if ':' in e else e[:50])\n",
    "        else:\n",
    "            cats['other'].append(e[:50])\n",
    "    parts = []\n",
    "    if cats['missing_field']:\n",
    "        fields = sorted(set(cats['missing_field']))\n",
    "        parts.append(f\"missing:{','.join(fields)}\")\n",
    "    if cats['invalid_enum']:\n",
    "        paths = sorted(set(cats['invalid_enum']))[:3]\n",
    "        parts.append(f\"enum:{','.join(paths)}\")\n",
    "    if cats['type_error']:\n",
    "        paths = sorted(set(cats['type_error']))[:3]\n",
    "        parts.append(f\"type:{','.join(paths)}\")\n",
    "    if cats['anyOf']:\n",
    "        paths = sorted(set(cats['anyOf']))[:3]\n",
    "        parts.append(f\"anyOf:{','.join(paths)}\")\n",
    "    if cats['other']:\n",
    "        parts.append(f\"other:{len(cats['other'])}\")\n",
    "    return '; '.join(parts)\n",
    "\n",
    "val_lookup = {}\n",
    "for _, row in df_validation.iterrows():\n",
    "    errors_list = row.get('errors', [])\n",
    "    if not isinstance(errors_list, list):\n",
    "        errors_list = []\n",
    "    val_lookup[row['filename']] = {\n",
    "        'status': row['status'],\n",
    "        'error_count': row.get('error_count', 0),\n",
    "        'error_summary': _summarize_errors(errors_list),\n",
    "    }\n",
    "\n",
    "comp_lookup = {}\n",
    "for _, row in df_completeness.iterrows():\n",
    "    comp_lookup[row['filename']] = row.to_dict()\n",
    "\n",
    "# Score all records\n",
    "scored_records = []\n",
    "\n",
    "iterator = tqdm(rdls_records, desc=\"Scoring\") if HAS_TQDM else rdls_records\n",
    "\n",
    "for record in iterator:\n",
    "    filename = record['filename']\n",
    "\n",
    "    if 'data' not in record:\n",
    "        scored_records.append({\n",
    "            'filename': filename,\n",
    "            'composite_score': 0.0,\n",
    "            'tier': 'low',\n",
    "            'hevl_coverage': 0.0,\n",
    "            'block_richness': 0.0,\n",
    "            'schema_score': 0.0,\n",
    "            'metadata_score': 0.0,\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    val_info = val_lookup.get(filename, {'status': 'unknown', 'error_count': 0})\n",
    "    comp_info = comp_lookup.get(filename, {})\n",
    "\n",
    "    composite, components = compute_composite_confidence(\n",
    "        record['data'],\n",
    "        comp_info,\n",
    "        val_info['status'],\n",
    "        val_info['error_count'],\n",
    "    )\n",
    "\n",
    "    # Assign tier\n",
    "    if composite >= THRESHOLD_HIGH:\n",
    "        tier = 'high'\n",
    "    elif composite >= THRESHOLD_MEDIUM:\n",
    "        tier = 'medium'\n",
    "    else:\n",
    "        tier = 'low'\n",
    "\n",
    "    ds = record['data'].get('datasets', [{}])[0]\n",
    "\n",
    "    scored_records.append({\n",
    "        'filename': filename,\n",
    "        'id': ds.get('id', ''),\n",
    "        'title': (ds.get('title', '') or '')[:100],\n",
    "        'risk_data_type': '|'.join(ds.get('risk_data_type', [])),\n",
    "        'composite_score': composite,\n",
    "        'tier': tier,\n",
    "        'hevl_coverage': components['hevl_coverage'],\n",
    "        'block_richness': components['block_richness'],\n",
    "        'schema_score': components['schema_score'],\n",
    "        'metadata_score': components['metadata_score'],\n",
    "        'has_hazard_block': comp_info.get('has_hazard', False),\n",
    "        'has_exposure_block': comp_info.get('has_exposure', False),\n",
    "        'has_vulnerability_block': comp_info.get('has_vulnerability', False),\n",
    "        'has_loss_block': comp_info.get('has_loss', False),\n",
    "        'validation_status': val_info['status'],\n",
    "        'validation_errors': val_info['error_count'],\n",
    "        'validation_error_summary': val_info.get('error_summary', ''),\n",
    "    })\n",
    "\n",
    "df_scored = pd.DataFrame(scored_records)\n",
    "\n",
    "# --- Compute dist_folder: two-dimensional tier x validity ---\n",
    "def compute_dist_folder(row):\n",
    "    \"\"\"Return the distribution folder path for a record.\"\"\"\n",
    "    tier = row['tier']\n",
    "    if row.get('validation_status') == 'valid':\n",
    "        return tier  # \"high\", \"medium\", or \"low\"\n",
    "    else:\n",
    "        return f\"invalid/{tier}\"  # \"invalid/high\", \"invalid/medium\", \"invalid/low\"\n",
    "\n",
    "df_scored['dist_folder'] = df_scored.apply(compute_dist_folder, axis=1)\n",
    "\n",
    "# --- Summary ---\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"COMPOSITE CONFIDENCE SCORING\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total records scored: {len(df_scored):,}\")\n",
    "print(f\"\\nScore distribution:\")\n",
    "print(f\"  Mean:   {df_scored['composite_score'].mean():.3f}\")\n",
    "print(f\"  Median: {df_scored['composite_score'].median():.3f}\")\n",
    "print(f\"  Min:    {df_scored['composite_score'].min():.3f}\")\n",
    "print(f\"  Max:    {df_scored['composite_score'].max():.3f}\")\n",
    "\n",
    "print(f\"\\nTier distribution:\")\n",
    "for tier in ['high', 'medium', 'low']:\n",
    "    count = (df_scored['tier'] == tier).sum()\n",
    "    pct = count / len(df_scored) * 100\n",
    "    print(f\"  {tier:8s}: {count:>6,} ({pct:>5.1f}%)\")\n",
    "\n",
    "print(f\"\\nTwo-dimensional distribution (confidence x validity):\")\n",
    "for tier in ['high', 'medium', 'low']:\n",
    "    tier_mask = df_scored['tier'] == tier\n",
    "    valid_n = (tier_mask & (df_scored['validation_status'] == 'valid')).sum()\n",
    "    invalid_n = (tier_mask & (df_scored['validation_status'] != 'valid')).sum()\n",
    "    total_n = tier_mask.sum()\n",
    "    print(f\"  {tier:8s}: {valid_n:>6,} valid + {invalid_n:>6,} invalid = {total_n:>6,} total\")\n",
    "\n",
    "print(f\"\\nComponent score averages:\")\n",
    "for col in ['hevl_coverage', 'block_richness', 'schema_score', 'metadata_score']:\n",
    "    print(f\"  {col:20s}: {df_scored[col].mean():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e83c57b15b4799a1c30bcaa0278dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Distributing:   0%|          | 0/12577 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TIERED DISTRIBUTION\n",
      "============================================================\n",
      "Schema-VALID records:\n",
      "  high/                 9,797 records  ( 77.9%)  -- Production-ready (>= 0.8)\n",
      "  medium/                   0 records  (  0.0%)  -- Needs review (0.5 - 0.8)\n",
      "  low/                      0 records  (  0.0%)  -- Needs curation (< 0.5)\n",
      "                        9,797 total valid\n",
      "\n",
      "Schema-INVALID records:\n",
      "  invalid/high/         2,780 records  ( 22.1%)\n",
      "  invalid/medium/           0 records  (  0.0%)\n",
      "  invalid/low/              0 records  (  0.0%)\n",
      "                        2,780 total invalid\n",
      "\n",
      "Manifest CSVs written to each folder.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "6.2 Distribute Records into Tier Folders and Generate Manifests\n",
    "\n",
    "Two-dimensional routing:\n",
    "  - Schema-valid records   -> dist/{tier}/\n",
    "  - Schema-invalid records -> dist/invalid/{tier}/\n",
    "Each folder gets its own manifest.csv.\n",
    "\"\"\"\n",
    "\n",
    "def distribute_tiered_records(\n",
    "    df_scored: pd.DataFrame,\n",
    "    rdls_records: List[Dict],\n",
    "    folder_dirs: Dict[str, Path],\n",
    ") -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Copy records into distribution folders based on dist_folder column\n",
    "    and generate a manifest.csv in each populated folder.\n",
    "    \"\"\"\n",
    "    # Build filename -> record lookup\n",
    "    record_lookup = {r['filename']: r for r in rdls_records if 'data' in r}\n",
    "\n",
    "    stats = {folder: 0 for folder in folder_dirs}\n",
    "    folder_manifests = {folder: [] for folder in folder_dirs}\n",
    "\n",
    "    iterator = (\n",
    "        tqdm(df_scored.iterrows(), total=len(df_scored), desc=\"Distributing\")\n",
    "        if HAS_TQDM else df_scored.iterrows()\n",
    "    )\n",
    "\n",
    "    for _, row in iterator:\n",
    "        dist_folder = row['dist_folder']\n",
    "        filename = row['filename']\n",
    "\n",
    "        if filename not in record_lookup:\n",
    "            continue\n",
    "\n",
    "        record = record_lookup[filename]\n",
    "        target_dir = folder_dirs[dist_folder]\n",
    "\n",
    "        # Copy JSON file\n",
    "        shutil.copy2(record['filepath'], target_dir / filename)\n",
    "        stats[dist_folder] += 1\n",
    "\n",
    "        # Collect manifest entry\n",
    "        folder_manifests[dist_folder].append({\n",
    "            'filename': filename,\n",
    "            'id': row.get('id', ''),\n",
    "            'title': row.get('title', ''),\n",
    "            'risk_data_type': row.get('risk_data_type', ''),\n",
    "            'composite_score': row.get('composite_score', 0.0),\n",
    "            'has_hazard_block': row.get('has_hazard_block', False),\n",
    "            'has_exposure_block': row.get('has_exposure_block', False),\n",
    "            'has_vulnerability_block': row.get('has_vulnerability_block', False),\n",
    "            'has_loss_block': row.get('has_loss_block', False),\n",
    "            'validation_status': row.get('validation_status', ''),\n",
    "            'validation_errors': row.get('validation_errors', 0),\n",
    "            'validation_error_summary': row.get('validation_error_summary', ''),\n",
    "        })\n",
    "\n",
    "    # Write manifest CSV per folder\n",
    "    for folder, entries in folder_manifests.items():\n",
    "        manifest_path = folder_dirs[folder] / 'manifest.csv'\n",
    "        if entries:\n",
    "            manifest_df = pd.DataFrame(entries)\n",
    "            manifest_df = manifest_df.sort_values('composite_score', ascending=False)\n",
    "            manifest_df.to_csv(manifest_path, index=False)\n",
    "        else:\n",
    "            # Write empty manifest with headers for consistency\n",
    "            pd.DataFrame(columns=[\n",
    "                'filename', 'id', 'title', 'risk_data_type', 'composite_score',\n",
    "                'has_hazard_block', 'has_exposure_block', 'has_vulnerability_block',\n",
    "                'has_loss_block', 'validation_status', 'validation_errors',\n",
    "                'validation_error_summary',\n",
    "            ]).to_csv(manifest_path, index=False)\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "# Map dist_folder values to directory paths\n",
    "folder_dirs = {\n",
    "    'high': TIER_HIGH_DIR,\n",
    "    'medium': TIER_MEDIUM_DIR,\n",
    "    'low': TIER_LOW_DIR,\n",
    "    'invalid/high': INVALID_HIGH_DIR,\n",
    "    'invalid/medium': INVALID_MEDIUM_DIR,\n",
    "    'invalid/low': INVALID_LOW_DIR,\n",
    "}\n",
    "\n",
    "# Clean existing contents in ALL 6 folders\n",
    "for folder_dir in folder_dirs.values():\n",
    "    for f in folder_dir.glob('*.json'):\n",
    "        f.unlink()\n",
    "    for f in folder_dir.glob('*.csv'):\n",
    "        f.unlink()\n",
    "\n",
    "dist_stats = distribute_tiered_records(df_scored, rdls_records, folder_dirs)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TIERED DISTRIBUTION\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "total_records = len(df_scored)\n",
    "\n",
    "print(\"Schema-VALID records:\")\n",
    "for tier in ['high', 'medium', 'low']:\n",
    "    count = dist_stats[tier]\n",
    "    pct = count / total_records * 100 if total_records > 0 else 0\n",
    "    label = {\n",
    "        'high': f'Production-ready (>= {THRESHOLD_HIGH})',\n",
    "        'medium': f'Needs review ({THRESHOLD_MEDIUM} - {THRESHOLD_HIGH})',\n",
    "        'low': f'Needs curation (< {THRESHOLD_MEDIUM})',\n",
    "    }[tier]\n",
    "    print(f\"  {tier + chr(47):20s} {count:>6,} records  ({pct:>5.1f}%)  -- {label}\")\n",
    "\n",
    "valid_total = sum(dist_stats[t] for t in ['high', 'medium', 'low'])\n",
    "print(f\"  {'':20s} {valid_total:>6,} total valid\")\n",
    "\n",
    "print(\"\\nSchema-INVALID records:\")\n",
    "for tier in ['high', 'medium', 'low']:\n",
    "    folder = f'invalid/{tier}'\n",
    "    count = dist_stats[folder]\n",
    "    pct = count / total_records * 100 if total_records > 0 else 0\n",
    "    print(f\"  {folder + chr(47):20s} {count:>6,} records  ({pct:>5.1f}%)\")\n",
    "\n",
    "invalid_total = sum(dist_stats[f'invalid/{t}'] for t in ['high', 'medium', 'low'])\n",
    "print(f\"  {'':20s} {invalid_total:>6,} total invalid\")\n",
    "\n",
    "print(f\"\\nManifest CSVs written to each folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/reports/schema_validation_report.csv\n",
      "Saved: /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/reports/hevl_completeness_report.csv\n",
      "Saved: /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/reports/confidence_scored_records.csv\n",
      "Saved: /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/dist/master_manifest.csv\n",
      "\n",
      "Reports copied to: /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/dist/reports\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "6.3 Save Reports and Scoring Data\n",
    "\"\"\"\n",
    "\n",
    "# Schema validation report\n",
    "validation_export = df_validation.copy()\n",
    "validation_export['errors'] = validation_export['errors'].apply(\n",
    "    lambda x: '|'.join(x) if isinstance(x, list) else str(x)\n",
    ")\n",
    "validation_file = REPORTS_DIR / 'schema_validation_report.csv'\n",
    "validation_export.to_csv(validation_file, index=False)\n",
    "print(f\"Saved: {validation_file}\")\n",
    "\n",
    "# Completeness report\n",
    "completeness_file = REPORTS_DIR / 'hevl_completeness_report.csv'\n",
    "df_completeness.to_csv(completeness_file, index=False)\n",
    "print(f\"Saved: {completeness_file}\")\n",
    "\n",
    "# Full scored records (master manifest)\n",
    "# Reorder columns so dist_folder appears right after tier\n",
    "cols = list(df_scored.columns)\n",
    "if 'dist_folder' in cols and 'tier' in cols:\n",
    "    cols.remove('dist_folder')\n",
    "    tier_idx = cols.index('tier')\n",
    "    cols.insert(tier_idx + 1, 'dist_folder')\n",
    "    df_scored = df_scored[cols]\n",
    "\n",
    "scored_file = REPORTS_DIR / 'confidence_scored_records.csv'\n",
    "df_scored.to_csv(scored_file, index=False)\n",
    "print(f\"Saved: {scored_file}\")\n",
    "\n",
    "# Also save master manifest to dist/\n",
    "master_manifest = DIST_DIR / 'master_manifest.csv'\n",
    "df_scored.to_csv(master_manifest, index=False)\n",
    "print(f\"Saved: {master_manifest}\")\n",
    "\n",
    "# Copy reports to dist\n",
    "dist_reports = DIST_DIR / 'reports'\n",
    "dist_reports.mkdir(exist_ok=True)\n",
    "for report_file in REPORTS_DIR.glob('*'):\n",
    "    shutil.copy2(report_file, dist_reports / report_file.name)\n",
    "\n",
    "print(f\"\\nReports copied to: {dist_reports}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/reports/rdls_validation_summary.md\n",
      "Copied as: /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/dist/README.md\n",
      "\n",
      "ZIP archive: /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/rdls_hdx_package_20260211.zip\n",
      "Size: 76.0 MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "6.4 Generate Summary Report and ZIP Archive\n",
    "\"\"\"\n",
    "\n",
    "# --- Summary Report ---\n",
    "total = len(df_scored)\n",
    "valid = (df_validation['status'] == 'valid').sum()\n",
    "invalid = (df_validation['status'] == 'invalid').sum()\n",
    "\n",
    "h_count = df_completeness.get('has_hazard', pd.Series(dtype=bool)).sum()\n",
    "e_count = df_completeness.get('has_exposure', pd.Series(dtype=bool)).sum()\n",
    "v_count = df_completeness.get('has_vulnerability', pd.Series(dtype=bool)).sum()\n",
    "l_count = df_completeness.get('has_loss', pd.Series(dtype=bool)).sum()\n",
    "\n",
    "high_n = (df_scored['tier'] == 'high').sum()\n",
    "med_n = (df_scored['tier'] == 'medium').sum()\n",
    "low_n = (df_scored['tier'] == 'low').sum()\n",
    "\n",
    "# Two-dimensional counts\n",
    "high_valid = (df_scored['dist_folder'] == 'high').sum()\n",
    "high_invalid = (df_scored['dist_folder'] == 'invalid/high').sum()\n",
    "med_valid = (df_scored['dist_folder'] == 'medium').sum()\n",
    "med_invalid = (df_scored['dist_folder'] == 'invalid/medium').sum()\n",
    "low_valid = (df_scored['dist_folder'] == 'low').sum()\n",
    "low_invalid = (df_scored['dist_folder'] == 'invalid/low').sum()\n",
    "\n",
    "report = f\"\"\"# RDLS Validation and QA Report\n",
    "\n",
    "**Generated**: {datetime.now().isoformat()}\n",
    "**Source**: HDX Dataset Metadata (Humanitarian Data Exchange)\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Total Records | {total:,} |\n",
    "| Schema Valid | {valid:,} ({valid/total*100:.1f}%) |\n",
    "| Schema Invalid | {invalid:,} ({invalid/total*100:.1f}%) |\n",
    "\n",
    "## Confidence Tiers (two-dimensional: confidence x schema validity)\n",
    "\n",
    "| Tier | Valid | Invalid | Total | Description |\n",
    "|------|-------|---------|-------|-------------|\n",
    "| **high/** | {high_valid:,} | {high_invalid:,} | {high_n:,} | Score >= {THRESHOLD_HIGH} |\n",
    "| **medium/** | {med_valid:,} | {med_invalid:,} | {med_n:,} | {THRESHOLD_MEDIUM} <= score < {THRESHOLD_HIGH} |\n",
    "| **low/** | {low_valid:,} | {low_invalid:,} | {low_n:,} | Score < {THRESHOLD_MEDIUM} |\n",
    "| **Total** | {valid:,} | {invalid:,} | {total:,} | |\n",
    "\n",
    "## HEVL Block Coverage\n",
    "\n",
    "| Component | Records with Block | Percentage |\n",
    "|-----------|-------------------|------------|\n",
    "| Hazard | {h_count:,} | {h_count/total*100:.1f}% |\n",
    "| Exposure | {e_count:,} | {e_count/total*100:.1f}% |\n",
    "| Vulnerability | {v_count:,} | {v_count/total*100:.1f}% |\n",
    "| Loss | {l_count:,} | {l_count/total*100:.1f}% |\n",
    "\n",
    "## Composite Score Components (Averages)\n",
    "\n",
    "| Component | Weight | Avg Score |\n",
    "|-----------|--------|-----------|\n",
    "| HEVL Coverage | 40% | {df_scored['hevl_coverage'].mean():.3f} |\n",
    "| Block Richness | 25% | {df_scored['block_richness'].mean():.3f} |\n",
    "| Schema Validity | 20% | {df_scored['schema_score'].mean():.3f} |\n",
    "| Metadata Completeness | 15% | {df_scored['metadata_score'].mean():.3f} |\n",
    "\n",
    "## Output Structure\n",
    "\n",
    "```\n",
    "dist/\n",
    "  high/              {high_valid:,} records (schema-valid, production-ready)\n",
    "    manifest.csv\n",
    "    rdls_*.json\n",
    "  medium/            {med_valid:,} records (schema-valid, needs review)\n",
    "    manifest.csv\n",
    "    rdls_*.json\n",
    "  low/               {low_valid:,} records (schema-valid, needs curation)\n",
    "    manifest.csv\n",
    "    rdls_*.json\n",
    "  invalid/           ALL schema-invalid records\n",
    "    high/            {high_invalid:,} records (high confidence, schema invalid)\n",
    "      manifest.csv\n",
    "      rdls_*.json\n",
    "    medium/          {med_invalid:,} records (medium confidence, schema invalid)\n",
    "      manifest.csv\n",
    "      rdls_*.json\n",
    "    low/             {low_invalid:,} records (low confidence, schema invalid)\n",
    "      manifest.csv\n",
    "      rdls_*.json\n",
    "  reports/           QA reports\n",
    "  master_manifest.csv   All records with scores, tiers, and dist_folder\n",
    "```\n",
    "\n",
    "## Notes\n",
    "\n",
    "- Metadata was automatically extracted from HDX (https://data.humdata.org)\n",
    "- HEVL blocks generated by pattern-based extraction (NB 09-11)\n",
    "- Confidence scores are composite: HEVL coverage (40%) + block richness (25%) + schema validity (20%) + metadata completeness (15%)\n",
    "- Schema-valid records go to top-level tier folders; schema-invalid records go to invalid/ sub-tiers\n",
    "\n",
    "---\n",
    "*Report generated by HDX-RDLS Pipeline Notebook 13*\n",
    "\"\"\"\n",
    "\n",
    "summary_file = REPORTS_DIR / 'rdls_validation_summary.md'\n",
    "with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "shutil.copy2(summary_file, DIST_DIR / 'README.md')\n",
    "print(f\"Saved: {summary_file}\")\n",
    "print(f\"Copied as: {DIST_DIR / 'README.md'}\")\n",
    "\n",
    "# --- ZIP Archive ---\n",
    "def create_zip_archive(dist_dir: Path, output_name: str = 'rdls_hdx_package') -> Path:\n",
    "    \"\"\"Create ZIP archive of distribution.\"\"\"\n",
    "    timestamp = datetime.now().strftime('%Y%m%d')\n",
    "    zip_path = dist_dir.parent / f\"{output_name}_{timestamp}.zip\"\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
    "        for file_path in dist_dir.rglob('*'):\n",
    "            if file_path.is_file():\n",
    "                arcname = file_path.relative_to(dist_dir)\n",
    "                zf.write(file_path, arcname)\n",
    "\n",
    "    return zip_path\n",
    "\n",
    "zip_path = create_zip_archive(DIST_DIR)\n",
    "size_mb = zip_path.stat().st_size / (1024 * 1024)\n",
    "print(f\"\\nZIP archive: {zip_path}\")\n",
    "print(f\"Size: {size_mb:.1f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "HDX -> RDLS PIPELINE COMPLETE\n",
      "======================================================================\n",
      "\n",
      "VALIDATION\n",
      "----------\n",
      "Total RDLS records:    12,577\n",
      "Schema valid:          9,797 (77.9%)\n",
      "Schema invalid:        2,780 (22.1%)\n",
      "\n",
      "CONFIDENCE TIERS (confidence x validity)\n",
      "-----------------------------------------\n",
      "                         Valid   Invalid    Total\n",
      "High (>= 0.8):        9,797    2,780   12,577   Production-ready\n",
      "Medium (0.5-0.8):         0        0        0   Needs review\n",
      "Low (< 0.5):             0        0        0   Needs curation\n",
      "                       ------   ------   ------\n",
      "Total:                  9,797    2,780   12,577\n",
      "\n",
      "HEVL COVERAGE\n",
      "-------------\n",
      "With Hazard block:         2,788\n",
      "With Exposure block:      11,517\n",
      "With Vulnerability block:  3,429\n",
      "With Loss block:             703\n",
      "\n",
      "OUTPUT\n",
      "------\n",
      "Distribution:  /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/dist\n",
      "  high/              9,797 records  (valid, production-ready)\n",
      "  medium/            0 records  (valid, needs review)\n",
      "  low/               0 records  (valid, needs curation)\n",
      "  invalid/high/      2,780 records  (invalid, high confidence)\n",
      "  invalid/medium/    0 records  (invalid, medium confidence)\n",
      "  invalid/low/       0 records  (invalid, low confidence)\n",
      "Reports:       /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/reports\n",
      "ZIP Archive:   /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/rdls_hdx_package_20260211.zip\n",
      "\n",
      "Notebook completed: 2026-02-11T18:57:25.870838\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "7.1 Pipeline Summary\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"HDX -> RDLS PIPELINE COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "total = len(df_scored)\n",
    "valid = (df_validation['status'] == 'valid').sum()\n",
    "invalid = (df_validation['status'] == 'invalid').sum()\n",
    "high_n = (df_scored['tier'] == 'high').sum()\n",
    "med_n = (df_scored['tier'] == 'medium').sum()\n",
    "low_n = (df_scored['tier'] == 'low').sum()\n",
    "\n",
    "# Two-dimensional counts\n",
    "high_valid = (df_scored['dist_folder'] == 'high').sum()\n",
    "high_invalid = (df_scored['dist_folder'] == 'invalid/high').sum()\n",
    "med_valid = (df_scored['dist_folder'] == 'medium').sum()\n",
    "med_invalid = (df_scored['dist_folder'] == 'invalid/medium').sum()\n",
    "low_valid = (df_scored['dist_folder'] == 'low').sum()\n",
    "low_invalid = (df_scored['dist_folder'] == 'invalid/low').sum()\n",
    "\n",
    "print(f\"\"\"\n",
    "VALIDATION\n",
    "----------\n",
    "Total RDLS records:    {total:,}\n",
    "Schema valid:          {valid:,} ({valid/total*100:.1f}%)\n",
    "Schema invalid:        {invalid:,} ({invalid/total*100:.1f}%)\n",
    "\n",
    "CONFIDENCE TIERS (confidence x validity)\n",
    "-----------------------------------------\n",
    "                         Valid   Invalid    Total\n",
    "High (>= {THRESHOLD_HIGH}):       {high_valid:>6,}   {high_invalid:>6,}   {high_n:>6,}   Production-ready\n",
    "Medium ({THRESHOLD_MEDIUM}-{THRESHOLD_HIGH}):    {med_valid:>6,}   {med_invalid:>6,}   {med_n:>6,}   Needs review\n",
    "Low (< {THRESHOLD_MEDIUM}):        {low_valid:>6,}   {low_invalid:>6,}   {low_n:>6,}   Needs curation\n",
    "                       ------   ------   ------\n",
    "Total:                 {valid:>6,}   {invalid:>6,}   {total:>6,}\n",
    "\n",
    "HEVL COVERAGE\n",
    "-------------\n",
    "With Hazard block:        {df_completeness.get('has_hazard', pd.Series(dtype=bool)).sum():>6,}\n",
    "With Exposure block:      {df_completeness.get('has_exposure', pd.Series(dtype=bool)).sum():>6,}\n",
    "With Vulnerability block: {df_completeness.get('has_vulnerability', pd.Series(dtype=bool)).sum():>6,}\n",
    "With Loss block:          {df_completeness.get('has_loss', pd.Series(dtype=bool)).sum():>6,}\n",
    "\n",
    "OUTPUT\n",
    "------\n",
    "Distribution:  {DIST_DIR}\n",
    "  high/              {high_valid:,} records  (valid, production-ready)\n",
    "  medium/            {med_valid:,} records  (valid, needs review)\n",
    "  low/               {low_valid:,} records  (valid, needs curation)\n",
    "  invalid/high/      {high_invalid:,} records  (invalid, high confidence)\n",
    "  invalid/medium/    {med_invalid:,} records  (invalid, medium confidence)\n",
    "  invalid/low/       {low_invalid:,} records  (invalid, low confidence)\n",
    "Reports:       {REPORTS_DIR}\n",
    "ZIP Archive:   {zip_path}\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Notebook completed: {datetime.now().isoformat()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
