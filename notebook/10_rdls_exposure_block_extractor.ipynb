{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 10: RDLS Exposure Block Extractor\n",
    "\n",
    "**Purpose**: Extract and populate RDLS v0.3 Exposure component blocks from HDX metadata.\n",
    "\n",
    "**Input**:\n",
    "- HDX dataset metadata JSON files\n",
    "- Signal Dictionary (`config/signal_dictionary.yaml`)\n",
    "- RDLS Schema (`rdls/schema/rdls_schema_v0.3.json`)\n",
    "\n",
    "**Output**:\n",
    "- Exposure block extractions with confidence scores\n",
    "- Updated RDLS records with populated exposure blocks\n",
    "\n",
    "**RDLS Exposure Block Structure**:\n",
    "```json\n",
    "\"exposure\": [\n",
    "  {\n",
    "    \"id\": \"...\",\n",
    "    \"category\": \"agriculture|buildings|infrastructure|population|natural_environment|economic_indicator|development_index\",\n",
    "    \"taxonomy\": \"GED4ALL|MOVER|GLIDE|EMDAT|USGS_EHP|OED|HAZUS|EMS-98|PAGER|CDC-SVI|INFORM|Custom\",\n",
    "    \"metrics\": [\n",
    "      {\n",
    "        \"id\": \"...\",\n",
    "        \"dimension\": \"structure|content|product|disruption|population|index\",\n",
    "        \"quantity_kind\": \"area|count|monetary|length|time\",\n",
    "        \"currency\": \"USD (only when quantity_kind = monetary)\"\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "**Schema Reference**:\n",
    "- `category`: closed codelist (7 values)\n",
    "- `taxonomy`: closed codelist (12 values)\n",
    "- `dimension` (metric_dimension): closed codelist (6 values, all lowercase)\n",
    "- `quantity_kind`: open codelist (5 suggested values, extensible)\n",
    "- `currency`: ISO 4217 three-letter code, mandatory when quantity_kind = monetary\n",
    "\n",
    "**Author**: Benny Istanto/Risk Data Librarian/GFDRR  \n",
    "**Version**: 2026.2\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook started: 2026-02-10T09:01:07.221770\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1.1 Import Dependencies\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Optional, Any, Set\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "    HAS_TQDM = True\n",
    "except ImportError:\n",
    "    HAS_TQDM = False\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 120)\n",
    "\n",
    "print(f\"Notebook started: {datetime.now().isoformat()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base: /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler\n",
      "Output: /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/extracted\n",
      "Cleanup mode: replace\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1.2 Define Paths\n",
    "\"\"\"\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "BASE_DIR = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == 'notebook' else NOTEBOOK_DIR\n",
    "\n",
    "DATASET_METADATA_DIR = BASE_DIR / 'hdx_dataset_metadata_dump' / 'dataset_metadata'\n",
    "SIGNAL_DICT_PATH = BASE_DIR / 'hdx_dataset_metadata_dump' / 'config' / 'signal_dictionary.yaml'\n",
    "RDLS_SCHEMA_PATH = BASE_DIR / 'hdx_dataset_metadata_dump' / 'rdls' / 'schema' / 'rdls_schema_v0.3.json'\n",
    "\n",
    "OUTPUT_DIR = BASE_DIR / 'hdx_dataset_metadata_dump' / 'rdls' / 'extracted'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# â”€â”€ Output cleanup mode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Controls what happens to old output files when this notebook is re-run.\n",
    "#   \"replace\" - Auto-delete old outputs and continue (default)\n",
    "#   \"prompt\"  - Show what will be deleted, ask user to confirm\n",
    "#   \"skip\"    - Keep old files, write new on top (may leave orphans)\n",
    "#   \"abort\"   - Stop if old outputs exist (for CI/automated runs)\n",
    "CLEANUP_MODE = \"replace\"\n",
    "\n",
    "assert DATASET_METADATA_DIR.exists(), f\"Not found: {DATASET_METADATA_DIR}\"\n",
    "assert SIGNAL_DICT_PATH.exists(), f\"Not found: {SIGNAL_DICT_PATH}\"\n",
    "\n",
    "print(f\"Base: {BASE_DIR}\")\n",
    "print(f\"Output: {OUTPUT_DIR}\")\n",
    "print(f\"Cleanup mode: {CLEANUP_MODE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema constants loaded:\n",
      "  Valid exposure categories (7): ['agriculture', 'buildings', 'development_index', 'economic_indicator', 'infrastructure', 'natural_environment', 'population']\n",
      "  Valid metric dimensions (6): ['content', 'disruption', 'index', 'population', 'product', 'structure']\n",
      "  Valid taxonomies (12): ['CDC-SVI', 'Custom', 'EMDAT', 'EMS-98', 'GED4ALL', 'GLIDE', 'HAZUS', 'INFORM', 'MOVER', 'OED', 'PAGER', 'USGS_EHP']\n",
      "  Category defaults: 7 mappings\n",
      "  Valid triplets: 16 across 7 categories\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1.3 Load Signal Dictionary and RDLS Schema Constants\n",
    "\"\"\"\n",
    "\n",
    "with open(SIGNAL_DICT_PATH, 'r', encoding='utf-8') as f:\n",
    "    SIGNAL_DICT = yaml.safe_load(f)\n",
    "\n",
    "with open(RDLS_SCHEMA_PATH, 'r', encoding='utf-8') as f:\n",
    "    RDLS_SCHEMA = json.load(f)\n",
    "\n",
    "# --- Extract valid codelists from schema ---\n",
    "VALID_EXPOSURE_CATEGORIES = set(\n",
    "    RDLS_SCHEMA.get('$defs', {}).get('exposure_category', {}).get('enum', [])\n",
    ")\n",
    "VALID_METRIC_DIMENSIONS = set(\n",
    "    RDLS_SCHEMA.get('$defs', {}).get('metric_dimension', {}).get('enum', [])\n",
    ")\n",
    "VALID_TAXONOMIES = set(\n",
    "    RDLS_SCHEMA.get('$defs', {}).get('taxonomy', {}).get('enum', [])\n",
    ")\n",
    "\n",
    "# Quantity kind is an OPEN codelist - these are suggestions\n",
    "QUANTITY_KIND_SUGGESTIONS = ['area', 'count', 'monetary', 'length', 'time']\n",
    "\n",
    "# --- Valid Metric Triplets ---\n",
    "# Constrains which (category, dimension, quantity_kind) combinations are allowed.\n",
    "# Derived from RDLS codelist definitions and domain logic.\n",
    "# First entry in each list is the DEFAULT for that category.\n",
    "VALID_TRIPLETS = {\n",
    "    # agriculture -> structure/area, product/monetary, product/count\n",
    "    'agriculture': [\n",
    "        ('structure', 'area'),       # hectares of cultivated land\n",
    "        ('product',   'monetary'),   # value of crop yield\n",
    "        ('product',   'count'),      # head of livestock\n",
    "    ],\n",
    "    # buildings -> structure/count, structure/monetary, structure/area, content/monetary\n",
    "    'buildings': [\n",
    "        ('structure', 'count'),      # number of buildings\n",
    "        ('structure', 'monetary'),   # replacement cost of building stock\n",
    "        ('structure', 'area'),       # total floor area\n",
    "        ('content',   'monetary'),   # value of contents/inventory\n",
    "    ],\n",
    "    # infrastructure -> structure/length, structure/monetary, disruption/time, disruption/monetary\n",
    "    'infrastructure': [\n",
    "        ('structure',  'length'),    # km of road/railway\n",
    "        ('structure',  'monetary'),  # construction cost of utility network\n",
    "        ('disruption', 'time'),      # duration of service outage\n",
    "        ('disruption', 'monetary'),  # economic loss from service interruption\n",
    "    ],\n",
    "    # population -> population/count  (the only valid combination)\n",
    "    'population': [\n",
    "        ('population', 'count'),     # number of people\n",
    "    ],\n",
    "    # natural_environment -> structure/area  (the only valid combination)\n",
    "    'natural_environment': [\n",
    "        ('structure', 'area'),       # sq km of protected forest/vegetation\n",
    "    ],\n",
    "    # economic_indicator -> product/monetary, index/count\n",
    "    'economic_indicator': [\n",
    "        ('product', 'monetary'),     # total GDP exposure\n",
    "        ('index',   'count'),        # inflation rate, unemployment rate\n",
    "    ],\n",
    "    # development_index -> index/count  (composite scores, unitless/normalized)\n",
    "    'development_index': [\n",
    "        ('index', 'count'),          # HDI score, SVI score\n",
    "    ],\n",
    "}\n",
    "\n",
    "# CATEGORY_DEFAULT_METRICS = first entry from each VALID_TRIPLETS list\n",
    "CATEGORY_DEFAULT_METRICS = {\n",
    "    cat: triplets[0] for cat, triplets in VALID_TRIPLETS.items()\n",
    "}\n",
    "\n",
    "# Validate all triplets use valid schema values\n",
    "for cat, triplets in VALID_TRIPLETS.items():\n",
    "    assert cat in VALID_EXPOSURE_CATEGORIES, f\"Invalid category: {cat}\"\n",
    "    for dim, qty in triplets:\n",
    "        assert dim in VALID_METRIC_DIMENSIONS, f\"Invalid dimension: {dim} for {cat}\"\n",
    "\n",
    "# --- Currency detection patterns (ISO 4217) ---\n",
    "COMMON_CURRENCIES = {\n",
    "    'USD', 'EUR', 'GBP', 'JPY', 'CHF', 'CAD', 'AUD', 'CNY', 'INR', 'BRL',\n",
    "    'ZAR', 'MXN', 'SGD', 'HKD', 'NOK', 'SEK', 'DKK', 'NZD', 'THB', 'IDR',\n",
    "    'PHP', 'MYR', 'KRW', 'TRY', 'RUB', 'PLN', 'CZK', 'HUF', 'CLP', 'COP',\n",
    "    'PEN', 'ARS', 'EGP', 'NGN', 'KES', 'GHS', 'TZS', 'UGX', 'ETB', 'BDT',\n",
    "    'PKR', 'LKR', 'MMK', 'VND', 'KHR', 'LAK', 'NPR', 'AFN', 'IQD', 'SYP',\n",
    "}\n",
    "\n",
    "print(f\"Schema constants loaded:\")\n",
    "print(f\"  Valid exposure categories ({len(VALID_EXPOSURE_CATEGORIES)}): {sorted(VALID_EXPOSURE_CATEGORIES)}\")\n",
    "print(f\"  Valid metric dimensions ({len(VALID_METRIC_DIMENSIONS)}): {sorted(VALID_METRIC_DIMENSIONS)}\")\n",
    "print(f\"  Valid taxonomies ({len(VALID_TAXONOMIES)}): {sorted(VALID_TAXONOMIES)}\")\n",
    "print(f\"  Category defaults: {len(CATEGORY_DEFAULT_METRICS)} mappings\")\n",
    "print(f\"  Valid triplets: {sum(len(v) for v in VALID_TRIPLETS.values())} across {len(VALID_TRIPLETS)} categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exposure Extraction Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data classes defined.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "2.1 Data Classes for Exposure Extraction\n",
    "\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class ExtractionMatch:\n",
    "    \"\"\"Single pattern match with confidence.\"\"\"\n",
    "    value: str\n",
    "    confidence: float\n",
    "    source_field: str\n",
    "    matched_text: str\n",
    "    pattern: str\n",
    "\n",
    "@dataclass\n",
    "class MetricExtraction:\n",
    "    \"\"\"Extracted metric information.\"\"\"\n",
    "    dimension: str\n",
    "    quantity_kind: str\n",
    "    confidence: float\n",
    "    source_hint: str = \"\"\n",
    "\n",
    "@dataclass\n",
    "class ExposureExtraction:\n",
    "    \"\"\"Complete exposure extraction for a dataset.\"\"\"\n",
    "    categories: List[ExtractionMatch] = field(default_factory=list)\n",
    "    metrics: List[MetricExtraction] = field(default_factory=list)\n",
    "    taxonomy_hint: Optional[str] = None\n",
    "    overall_confidence: float = 0.0\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'categories': [asdict(m) for m in self.categories],\n",
    "            'metrics': [asdict(m) for m in self.metrics],\n",
    "            'taxonomy_hint': self.taxonomy_hint,\n",
    "            'overall_confidence': self.overall_confidence\n",
    "        }\n",
    "\n",
    "print(\"Data classes defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric inference patterns defined:\n",
      "  Dimension patterns: 6 dimensions (all lowercase)\n",
      "  Quantity kind patterns: 5 kinds\n",
      "  Taxonomy patterns: 12 schemes\n",
      "  Currency patterns: 10 currencies\n",
      "  Note: All 7 exposure categories now in signal_dictionary.yaml\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "2.2 Metric Inference Patterns\n",
    "\n",
    "Patterns for detecting metric dimensions, quantity kinds, taxonomies, and currencies.\n",
    "All dimension keys use lowercase to match RDLS schema metric_dimension enum.\n",
    "\"\"\"\n",
    "\n",
    "# --- Metric dimension inference patterns ---\n",
    "# Keys MUST match schema enum: structure, content, product, disruption, population, index\n",
    "METRIC_DIMENSION_PATTERNS = {\n",
    "    'structure': [\n",
    "        r'\\b(building|structure|footprint|floor.?area)\\b',\n",
    "        r'\\b(construction|built|asset|facility)\\b',\n",
    "        r'\\b(road|bridge|railway|rail.?line|highway)\\b',\n",
    "        r'\\b(airport|port|harbor|terminal|pipeline)\\b',\n",
    "        r'\\b(power.?line|electricity.?grid|water.?supply)\\b',\n",
    "        r'\\b(hospital|school|health.?center|clinic)\\b',\n",
    "    ],\n",
    "    'content': [\n",
    "        r'\\b(content|inventory|equipment|furnishing)\\b',\n",
    "        r'\\b(stock|goods|material|supply)\\b',\n",
    "        r'\\b(land.?cover|land.?use|vegetation)\\b',\n",
    "        r'\\b(ecosystem|habitat|species)\\b',\n",
    "    ],\n",
    "    'product': [\n",
    "        r'\\b(crop|harvest|yield|production)\\b',\n",
    "        r'\\b(output|commodity|livestock|cattle)\\b',\n",
    "        r'\\b(food.?production|agricultural.?output)\\b',\n",
    "    ],\n",
    "    'disruption': [\n",
    "        r'\\b(disruption|downtime|outage|interruption)\\b',\n",
    "        r'\\b(delay|loss.?of.?function|service.?disruption)\\b',\n",
    "        r'\\b(business.?interruption|closur)\\b',\n",
    "    ],\n",
    "    'population': [\n",
    "        r'\\b(population[\\s._-]?(?:count|density|data|distribution|grid|layer|estimate))\\b',\n",
    "        r'\\b((?:census|demographic)[\\s._-]?(?:data|survey|layer))\\b',\n",
    "        r'\\b(household[\\s._-]?(?:survey|count|data|size))\\b',\n",
    "        r'\\b((?:displaced|refugee|idp)[\\s._-]?(?:population|count|data|number))\\b',\n",
    "        r'\\b(population[\\s._-]?(?:exposure|at[\\s._-]?risk|affected|vulnerable))\\b',\n",
    "    ],\n",
    "    'index': [\n",
    "        r'\\b(index|indicator|score|ranking)\\b',\n",
    "        r'\\b(hdi|svi|inform.?risk|poverty.?index)\\b',\n",
    "        r'\\b(vulnerability.?index|resilience.?index)\\b',\n",
    "        r'\\b(development.?index|risk.?index)\\b',\n",
    "        r'\\b(gdp|gni|economic.?indicator)\\b',\n",
    "    ],\n",
    "}\n",
    "\n",
    "# --- Quantity kind inference patterns ---\n",
    "# quantity_kind is an OPEN codelist, but these are the standard values\n",
    "QUANTITY_KIND_PATTERNS = {\n",
    "    'count': [\n",
    "        r'\\b(count[\\s._-]?(?:of|data|per))\\b',\n",
    "        r'\\b(number[\\s._-]?of[\\s._-]?(?:building|structure|house|people|person|household))\\b',\n",
    "        r'\\b(total[\\s._-]?(?:count|number|population|building|structure))\\b',\n",
    "    ],\n",
    "    'area': [\n",
    "        r'\\b(area|hectare|acre|sq\\.?\\s*(?:m|km|ft))\\b',\n",
    "        r'\\b(square|coverage|extent|footprint)\\b',\n",
    "    ],\n",
    "    'length': [\n",
    "        r'\\b(length|distance|km|kilometer|mile)\\b',\n",
    "        r'\\b(route|corridor|line|network)\\b',\n",
    "    ],\n",
    "    'monetary': [\n",
    "        r'\\b(value|cost|price|worth|\\$|usd|eur)\\b',\n",
    "        r'\\b(economic|financial|monetary|budget)\\b',\n",
    "        r'\\b(replacement|rebuild|damage.?cost)\\b',\n",
    "        r'\\b(gdp|gni|income|expenditure)\\b',\n",
    "    ],\n",
    "    'time': [\n",
    "        r'\\b(duration|time|hours|days|weeks)\\b',\n",
    "        r'\\b(downtime|turnaround|recovery.?time)\\b',\n",
    "    ],\n",
    "}\n",
    "\n",
    "# --- Taxonomy detection patterns ---\n",
    "# Keys MUST match schema taxonomy enum exactly\n",
    "TAXONOMY_PATTERNS = {\n",
    "    'GED4ALL':  [r'\\b(ged4all|gem.?taxonomy)\\b'],\n",
    "    'MOVER':    [r'\\bmover\\b'],\n",
    "    'GLIDE':    [r'\\bglide\\b'],\n",
    "    'EMDAT':    [r'\\b(em[\\-\\s]?dat|emdat)\\b'],\n",
    "    'USGS_EHP': [r'\\b(usgs.?ehp|usgs.?earthquake.?hazard)\\b'],\n",
    "    'OED':      [r'\\boed\\b'],\n",
    "    'HAZUS':    [r'\\b(hazus|fema.?taxonomy)\\b'],\n",
    "    'EMS-98':   [r'\\b(ems[\\-\\s]?98|european.?macroseismic)\\b'],\n",
    "    'PAGER':    [r'\\b(pager|usgs.?pager)\\b'],\n",
    "    'CDC-SVI':  [r'\\b(cdc[\\-\\s]?svi|social.?vulnerability.?index)\\b'],\n",
    "    'INFORM':   [r'\\binform\\s+(?:risk|index|severity)\\b'],\n",
    "    'Custom':   [],  # Fallback only, not detected by pattern\n",
    "}\n",
    "\n",
    "# --- Currency detection patterns ---\n",
    "CURRENCY_PATTERNS = [\n",
    "    (r'\\b(USD|US\\s*\\$|United\\s*States\\s*Dollar)\\b', 'USD'),\n",
    "    (r'\\b(EUR|Euro)\\b', 'EUR'),\n",
    "    (r'\\b(GBP|British\\s*Pound)\\b', 'GBP'),\n",
    "    (r'\\b(JPY|Japanese\\s*Yen)\\b', 'JPY'),\n",
    "    (r'\\b(CHF|Swiss\\s*Franc)\\b', 'CHF'),\n",
    "    (r'\\b(AUD|Australian\\s*Dollar)\\b', 'AUD'),\n",
    "    (r'\\b(CAD|Canadian\\s*Dollar)\\b', 'CAD'),\n",
    "    (r'\\b(CNY|RMB|Chinese\\s*Yuan)\\b', 'CNY'),\n",
    "    (r'\\b(INR|Indian\\s*Rupee)\\b', 'INR'),\n",
    "    (r'\\b(BRL|Brazilian\\s*Real)\\b', 'BRL'),\n",
    "]\n",
    "\n",
    "# NOTE: All 7 exposure categories (including economic_indicator and\n",
    "# development_index) are now in signal_dictionary.yaml.\n",
    "\n",
    "print(\"Metric inference patterns defined:\")\n",
    "print(f\"  Dimension patterns: {len(METRIC_DIMENSION_PATTERNS)} dimensions (all lowercase)\")\n",
    "print(f\"  Quantity kind patterns: {len(QUANTITY_KIND_PATTERNS)} kinds\")\n",
    "print(f\"  Taxonomy patterns: {len(TAXONOMY_PATTERNS)} schemes\")\n",
    "print(f\"  Currency patterns: {len(CURRENCY_PATTERNS)} currencies\")\n",
    "print(f\"  Note: All 7 exposure categories now in signal_dictionary.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExposureExtractor initialized (3-tier cascade).\n",
      "  - Categories: 7 (['agriculture', 'buildings', 'development_index', 'economic_indicator', 'infrastructure', 'natural_environment', 'population'])\n",
      "  - Tier weights: T1=1.0, T2=0.85, T3=0.6\n",
      "  - Corroboration boost: 0.05\n",
      "  - Dimension patterns: 6 dimensions\n",
      "  - Taxonomy patterns: 11 schemes\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "2.3 Exposure Extractor Class\n",
    "\n",
    "Extracts RDLS Exposure block components from HDX metadata.\n",
    "\n",
    "Architecture: 3-tier cascade\n",
    "  Tier 1 (title, name, tags)  â€” full confidence, always authoritative\n",
    "  Tier 2 (individual resources) â€” 0.85 weight, can add new categories\n",
    "  Tier 3 (notes, methodology)  â€” 0.6 weight, corroboration ONLY\n",
    "                                  (never adds new categories except as\n",
    "                                   fallback when Tiers 1+2 find nothing)\n",
    "\n",
    "Key constraints:\n",
    "- All 7 exposure category patterns loaded from signal_dictionary.yaml\n",
    "- Metric inference constrained to VALID_TRIPLETS (category->dimension->quantity_kind)\n",
    "- Scoped metric inference per category source field\n",
    "\"\"\"\n",
    "\n",
    "from dataclasses import dataclass as _dc, field as _fld\n",
    "\n",
    "@_dc\n",
    "class TieredFields:\n",
    "    \"\"\"Structured text fields preserving tier hierarchy.\"\"\"\n",
    "    title: str = \"\"\n",
    "    name: str = \"\"\n",
    "    tags: str = \"\"\n",
    "    resources: list = _fld(default_factory=list)   # List[Dict] with 'name','description','format'\n",
    "    notes: str = \"\"\n",
    "    methodology: str = \"\"\n",
    "\n",
    "\n",
    "class ExposureExtractor:\n",
    "    \"\"\"\n",
    "    Extracts RDLS Exposure block components from HDX metadata\n",
    "    using a 3-tier confidence cascade.\n",
    "    \"\"\"\n",
    "\n",
    "    CONFIDENCE_MAP = {'high': 0.9, 'medium': 0.7, 'low': 0.5}\n",
    "\n",
    "    # Tier-level confidence multipliers\n",
    "    TIER1_CONFIDENCE = 1.0     # title, name, tags\n",
    "    TIER2_CONFIDENCE = 0.85    # individual resource name+description\n",
    "    TIER3_CONFIDENCE = 0.6     # notes, methodology\n",
    "    CORROBORATION_BOOST = 0.05\n",
    "\n",
    "    def __init__(self, signal_dict: Dict[str, Any]):\n",
    "        self.signal_dict = signal_dict\n",
    "        self._compile_patterns()\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Pattern compilation\n",
    "    # ------------------------------------------------------------------\n",
    "    def _compile_patterns(self) -> None:\n",
    "        \"\"\"Pre-compile all regex patterns.\"\"\"\n",
    "        self.category_patterns = {}\n",
    "        self.dimension_patterns = {}\n",
    "        self.quantity_patterns = {}\n",
    "        self.taxonomy_patterns = {}\n",
    "        self.currency_compiled = []\n",
    "\n",
    "        # --- Compile exposure category patterns from signal dict ---\n",
    "        for category, config in self.signal_dict.get('exposure_category', {}).items():\n",
    "            if category not in VALID_EXPOSURE_CATEGORIES:\n",
    "                continue\n",
    "            patterns = config.get('patterns', [])\n",
    "            confidence = self.CONFIDENCE_MAP.get(config.get('confidence', 'medium'), 0.7)\n",
    "            self.category_patterns[category] = {\n",
    "                'compiled': [re.compile(p, re.IGNORECASE) for p in patterns],\n",
    "                'confidence': confidence\n",
    "            }\n",
    "\n",
    "        # All 7 exposure categories are now in signal_dictionary.yaml\n",
    "\n",
    "        # --- Compile metric dimension patterns (all lowercase keys) ---\n",
    "        for dimension, patterns in METRIC_DIMENSION_PATTERNS.items():\n",
    "            assert dimension in VALID_METRIC_DIMENSIONS, f\"Bad dim key: {dimension}\"\n",
    "            self.dimension_patterns[dimension] = [\n",
    "                re.compile(p, re.IGNORECASE) for p in patterns\n",
    "            ]\n",
    "\n",
    "        # --- Compile quantity kind patterns ---\n",
    "        for kind, patterns in QUANTITY_KIND_PATTERNS.items():\n",
    "            self.quantity_patterns[kind] = [\n",
    "                re.compile(p, re.IGNORECASE) for p in patterns\n",
    "            ]\n",
    "\n",
    "        # --- Compile taxonomy patterns ---\n",
    "        for taxonomy, patterns in TAXONOMY_PATTERNS.items():\n",
    "            if patterns:\n",
    "                self.taxonomy_patterns[taxonomy] = [\n",
    "                    re.compile(p, re.IGNORECASE) for p in patterns\n",
    "                ]\n",
    "\n",
    "        # --- Compile currency patterns ---\n",
    "        for pattern, code in CURRENCY_PATTERNS:\n",
    "            self.currency_compiled.append(\n",
    "                (re.compile(pattern, re.IGNORECASE), code)\n",
    "            )\n",
    "\n",
    "        # natural_environment patterns now tightened in signal_dictionary.yaml\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Text extraction\n",
    "    # ------------------------------------------------------------------\n",
    "    def _extract_tiered_fields(self, hdx_record: Dict[str, Any]) -> TieredFields:\n",
    "        \"\"\"Extract text fields preserving tier structure.\"\"\"\n",
    "        raw_tags = hdx_record.get('tags', [])\n",
    "        tag_names = []\n",
    "        for t in raw_tags:\n",
    "            if isinstance(t, dict):\n",
    "                tag_names.append(t.get('name', ''))\n",
    "            elif isinstance(t, str):\n",
    "                tag_names.append(t)\n",
    "\n",
    "        resources_list = []\n",
    "        for r in hdx_record.get('resources', []):\n",
    "            resources_list.append({\n",
    "                'name': r.get('name', ''),\n",
    "                'description': r.get('description', ''),\n",
    "                'format': r.get('format', ''),\n",
    "            })\n",
    "\n",
    "        return TieredFields(\n",
    "            title=hdx_record.get('title', ''),\n",
    "            name=hdx_record.get('name', ''),\n",
    "            tags=' '.join(tag_names),\n",
    "            resources=resources_list,\n",
    "            notes=hdx_record.get('notes', '') or '',\n",
    "            methodology=hdx_record.get('methodology_other', '') or '',\n",
    "        )\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Tier scanning helpers\n",
    "    # ------------------------------------------------------------------\n",
    "    def _scan_fields(\n",
    "        self,\n",
    "        field_texts: Dict[str, str],\n",
    "        tier_weight: float,\n",
    "    ) -> Dict[str, ExtractionMatch]:\n",
    "        \"\"\"\n",
    "        Scan a set of named text fields against all category patterns.\n",
    "        Returns {category: best ExtractionMatch} for categories found.\n",
    "        \"\"\"\n",
    "        matches: Dict[str, ExtractionMatch] = {}\n",
    "        for category, config in self.category_patterns.items():\n",
    "            for compiled in config['compiled']:\n",
    "                for field_name, text in field_texts.items():\n",
    "                    if not text:\n",
    "                        continue\n",
    "                    m = compiled.search(text)\n",
    "                    if m:\n",
    "                        weighted = config['confidence'] * tier_weight\n",
    "                        if category not in matches or weighted > matches[category].confidence:\n",
    "                            matches[category] = ExtractionMatch(\n",
    "                                value=category,\n",
    "                                confidence=weighted,\n",
    "                                source_field=field_name,\n",
    "                                matched_text=m.group(0),\n",
    "                                pattern=compiled.pattern,\n",
    "                            )\n",
    "                        break  # first match per pattern is enough\n",
    "        return matches\n",
    "\n",
    "    def _scan_tier1(self, fields: TieredFields) -> Dict[str, ExtractionMatch]:\n",
    "        \"\"\"Tier 1: title, name, tags â€” full confidence.\"\"\"\n",
    "        return self._scan_fields(\n",
    "            {'title': fields.title, 'name': fields.name, 'tags': fields.tags},\n",
    "            self.TIER1_CONFIDENCE,\n",
    "        )\n",
    "\n",
    "    def _scan_tier2(self, fields: TieredFields) -> Dict[str, ExtractionMatch]:\n",
    "        \"\"\"Tier 2: individual resources â€” 0.85 weight, can add new categories.\"\"\"\n",
    "        merged: Dict[str, ExtractionMatch] = {}\n",
    "        for i, res in enumerate(fields.resources):\n",
    "            combined = f\"{res.get('name', '')} {res.get('description', '')}\"\n",
    "            if not combined.strip():\n",
    "                continue\n",
    "            hits = self._scan_fields(\n",
    "                {f'resource[{i}]': combined},\n",
    "                self.TIER2_CONFIDENCE,\n",
    "            )\n",
    "            for cat, match in hits.items():\n",
    "                if cat not in merged or match.confidence > merged[cat].confidence:\n",
    "                    merged[cat] = match\n",
    "        return merged\n",
    "\n",
    "    def _scan_tier3(self, fields: TieredFields) -> Dict[str, ExtractionMatch]:\n",
    "        \"\"\"Tier 3: notes, methodology â€” corroboration only.\"\"\"\n",
    "        return self._scan_fields(\n",
    "            {'notes': fields.notes, 'methodology': fields.methodology},\n",
    "            self.TIER3_CONFIDENCE,\n",
    "        )\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Tier merging\n",
    "    # ------------------------------------------------------------------\n",
    "    def _merge_tiers(\n",
    "        self,\n",
    "        tier1: Dict[str, ExtractionMatch],\n",
    "        tier2: Dict[str, ExtractionMatch],\n",
    "        tier3: Dict[str, ExtractionMatch],\n",
    "    ) -> List[ExtractionMatch]:\n",
    "        \"\"\"\n",
    "        Merge tiers into final category list.\n",
    "\n",
    "        Rules:\n",
    "          1. Tier 1 always included.\n",
    "          2. Tier 2 adds new categories OR boosts existing.\n",
    "          3. Tier 3 ONLY boosts (never adds), except as\n",
    "             fallback when Tiers 1+2 found nothing.\n",
    "        \"\"\"\n",
    "        final: Dict[str, ExtractionMatch] = {}\n",
    "\n",
    "        # Tier 1 â€” always accepted\n",
    "        for cat, match in tier1.items():\n",
    "            final[cat] = match\n",
    "\n",
    "        # Tier 2 â€” add or boost\n",
    "        for cat, match in tier2.items():\n",
    "            if cat in final:\n",
    "                # Corroborate: keep higher confidence + boost\n",
    "                best = final[cat]\n",
    "                final[cat] = ExtractionMatch(\n",
    "                    value=cat,\n",
    "                    confidence=min(best.confidence + self.CORROBORATION_BOOST, 1.0),\n",
    "                    source_field=best.source_field,\n",
    "                    matched_text=best.matched_text,\n",
    "                    pattern=best.pattern,\n",
    "                )\n",
    "            else:\n",
    "                # New category from resource â€” allow it\n",
    "                final[cat] = match\n",
    "\n",
    "        # Tier 3 â€” corroborate only (or fallback)\n",
    "        if final:\n",
    "            # Have categories already â€” Tier 3 can only boost\n",
    "            for cat, match in tier3.items():\n",
    "                if cat in final:\n",
    "                    best = final[cat]\n",
    "                    final[cat] = ExtractionMatch(\n",
    "                        value=cat,\n",
    "                        confidence=min(best.confidence + self.CORROBORATION_BOOST, 1.0),\n",
    "                        source_field=best.source_field,\n",
    "                        matched_text=best.matched_text,\n",
    "                        pattern=best.pattern,\n",
    "                    )\n",
    "                # else: discard â€” notes cannot introduce new categories\n",
    "        else:\n",
    "            # Fallback: Tiers 1+2 found nothing, allow Tier 3\n",
    "            for cat, match in tier3.items():\n",
    "                final[cat] = match\n",
    "\n",
    "        return list(final.values())\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Metric inference (scoped by tier source)\n",
    "    # ------------------------------------------------------------------\n",
    "    def _detect_dimensions_for_category(\n",
    "        self,\n",
    "        all_text: str,\n",
    "        category: str,\n",
    "    ) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Detect metric dimensions relevant to a category.\"\"\"\n",
    "        detected = []\n",
    "        for dimension, patterns in self.dimension_patterns.items():\n",
    "            for pattern in patterns:\n",
    "                if pattern.search(all_text):\n",
    "                    detected.append((dimension, 0.8))\n",
    "                    break\n",
    "\n",
    "        if detected:\n",
    "            default_dim = CATEGORY_DEFAULT_METRICS.get(category, ('content', 'count'))[0]\n",
    "            if any(d == default_dim for d, _ in detected):\n",
    "                return [(default_dim, 0.85)]\n",
    "            else:\n",
    "                return [detected[0]]\n",
    "\n",
    "        default_dim = CATEGORY_DEFAULT_METRICS.get(category, ('content', 'count'))[0]\n",
    "        return [(default_dim, 0.5)]\n",
    "\n",
    "    def _detect_quantity_kind(\n",
    "        self,\n",
    "        all_text: str,\n",
    "        category: str,\n",
    "    ) -> Tuple[str, float]:\n",
    "        \"\"\"Detect quantity kind from text with category fallback.\"\"\"\n",
    "        for kind, patterns in self.quantity_patterns.items():\n",
    "            for pattern in patterns:\n",
    "                if pattern.search(all_text):\n",
    "                    return (kind, 0.8)\n",
    "        default_qty = CATEGORY_DEFAULT_METRICS.get(category, ('content', 'count'))[1]\n",
    "        return (default_qty, 0.5)\n",
    "\n",
    "    def _detect_currency(self, all_text: str) -> str:\n",
    "        \"\"\"Detect ISO 4217 currency code.\"\"\"\n",
    "        for pattern, code in self.currency_compiled:\n",
    "            if pattern.search(all_text):\n",
    "                return code\n",
    "        for word in re.findall(r'\\b([A-Z]{3})\\b', all_text):\n",
    "            if word in COMMON_CURRENCIES:\n",
    "                return word\n",
    "        return \"\"\n",
    "\n",
    "    def _build_scoped_text(\n",
    "        self,\n",
    "        fields: TieredFields,\n",
    "        source_field: str,\n",
    "    ) -> str:\n",
    "        \"\"\"Build scoped text for metric inference from source field + title/tags.\"\"\"\n",
    "        scoped_parts: List[str] = []\n",
    "        if source_field.startswith('resource['):\n",
    "            try:\n",
    "                idx = int(source_field.split('[')[1].rstrip(']'))\n",
    "                res = fields.resources[idx]\n",
    "                scoped_parts.append(res.get('name', ''))\n",
    "                scoped_parts.append(res.get('description', ''))\n",
    "            except (IndexError, ValueError):\n",
    "                pass\n",
    "        elif source_field == 'title':\n",
    "            scoped_parts.append(fields.title)\n",
    "        elif source_field == 'name':\n",
    "            scoped_parts.append(fields.name)\n",
    "        elif source_field == 'tags':\n",
    "            scoped_parts.append(fields.tags)\n",
    "        elif source_field == 'notes':\n",
    "            scoped_parts.append(fields.notes)\n",
    "        elif source_field == 'methodology':\n",
    "            scoped_parts.append(fields.methodology)\n",
    "        # Always include title + tags for context\n",
    "        if source_field != 'title':\n",
    "            scoped_parts.append(fields.title)\n",
    "        if source_field != 'tags':\n",
    "            scoped_parts.append(fields.tags)\n",
    "        return ' '.join(p for p in scoped_parts if p)\n",
    "\n",
    "    def _infer_metrics(\n",
    "        self,\n",
    "        fields: TieredFields,\n",
    "        categories: List[ExtractionMatch],\n",
    "    ) -> Dict[str, List[MetricExtraction]]:\n",
    "        \"\"\"\n",
    "        Infer metrics PER CATEGORY, constrained to VALID_TRIPLETS.\n",
    "\n",
    "        Logic:\n",
    "        1. Build scoped text from the source field where category was matched\n",
    "        2. Detect dimension and quantity_kind from text patterns\n",
    "        3. Validate (category, dimension, quantity_kind) against VALID_TRIPLETS\n",
    "        4. If valid -> use it; if dimension valid but qty wrong -> fix qty;\n",
    "           otherwise -> fall back to category default\n",
    "        5. Currency detection is global (dataset-level signal)\n",
    "        \"\"\"\n",
    "        # Global text for currency detection only\n",
    "        global_parts = [fields.title, fields.name, fields.tags,\n",
    "                        fields.notes, fields.methodology]\n",
    "        for r in fields.resources:\n",
    "            global_parts.append(r.get('name', ''))\n",
    "            global_parts.append(r.get('description', ''))\n",
    "        global_text = ' '.join(p for p in global_parts if p)\n",
    "        currency = self._detect_currency(global_text)\n",
    "\n",
    "        metrics_by_category: Dict[str, List[MetricExtraction]] = {}\n",
    "\n",
    "        for cat_match in categories:\n",
    "            category = cat_match.value\n",
    "            source_field = cat_match.source_field\n",
    "            allowed = VALID_TRIPLETS.get(category, [])\n",
    "            default_dim, default_qty = CATEGORY_DEFAULT_METRICS.get(\n",
    "                category, ('content', 'count')\n",
    "            )\n",
    "\n",
    "            scoped_text = self._build_scoped_text(fields, source_field)\n",
    "\n",
    "            # Detect dimension and quantity from text patterns\n",
    "            dims = self._detect_dimensions_for_category(scoped_text, category)\n",
    "            qty_kind, qty_conf = self._detect_quantity_kind(scoped_text, category)\n",
    "\n",
    "            category_metrics = []\n",
    "            for dim, dim_conf in dims:\n",
    "                # --- Validate against VALID_TRIPLETS ---\n",
    "                if (dim, qty_kind) in allowed:\n",
    "                    # Exact match â€” use as detected\n",
    "                    pass\n",
    "                elif any(d == dim for d, _ in allowed):\n",
    "                    # Dimension valid but qty wrong â€” use the allowed qty for this dim\n",
    "                    qty_kind = next(q for d, q in allowed if d == dim)\n",
    "                    qty_conf = 0.5\n",
    "                else:\n",
    "                    # Dimension not valid for this category â€” fall back to default\n",
    "                    dim = default_dim\n",
    "                    qty_kind = default_qty\n",
    "                    dim_conf = 0.5\n",
    "                    qty_conf = 0.5\n",
    "\n",
    "                metric = MetricExtraction(\n",
    "                    dimension=dim,\n",
    "                    quantity_kind=qty_kind,\n",
    "                    confidence=min(dim_conf, qty_conf),\n",
    "                    source_hint=f'for_{category}',\n",
    "                )\n",
    "                if qty_kind == 'monetary' and currency:\n",
    "                    metric.source_hint = f'for_{category}_currency_{currency}'\n",
    "                category_metrics.append(metric)\n",
    "\n",
    "            if not category_metrics:\n",
    "                category_metrics.append(MetricExtraction(\n",
    "                    dimension=default_dim,\n",
    "                    quantity_kind=default_qty,\n",
    "                    confidence=0.4,\n",
    "                    source_hint=f'default_for_{category}',\n",
    "                ))\n",
    "\n",
    "            metrics_by_category[category] = category_metrics\n",
    "\n",
    "        return metrics_by_category\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Taxonomy detection\n",
    "    # ------------------------------------------------------------------\n",
    "    def _detect_taxonomy(self, fields: TieredFields) -> Optional[str]:\n",
    "        \"\"\"Detect taxonomy scheme from all text.\"\"\"\n",
    "        all_parts = [fields.title, fields.name, fields.tags,\n",
    "                     fields.notes, fields.methodology]\n",
    "        for r in fields.resources:\n",
    "            all_parts.append(r.get('name', ''))\n",
    "            all_parts.append(r.get('description', ''))\n",
    "        all_text = ' '.join(p for p in all_parts if p)\n",
    "\n",
    "        for taxonomy, patterns in self.taxonomy_patterns.items():\n",
    "            for pattern in patterns:\n",
    "                if pattern.search(all_text):\n",
    "                    if taxonomy in VALID_TAXONOMIES:\n",
    "                        return taxonomy\n",
    "        return None\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Main entry point\n",
    "    # ------------------------------------------------------------------\n",
    "    def extract(self, hdx_record: Dict[str, Any]) -> ExposureExtraction:\n",
    "        \"\"\"\n",
    "        Extract exposure information using 3-tier cascade.\n",
    "        \"\"\"\n",
    "        fields = self._extract_tiered_fields(hdx_record)\n",
    "\n",
    "        # Tiered category detection\n",
    "        tier1 = self._scan_tier1(fields)\n",
    "        tier2 = self._scan_tier2(fields)\n",
    "        tier3 = self._scan_tier3(fields)\n",
    "        categories = self._merge_tiers(tier1, tier2, tier3)\n",
    "\n",
    "        # Per-category metrics\n",
    "        metrics_by_category = self._infer_metrics(fields, categories)\n",
    "        all_metrics = []\n",
    "        for cat_metrics in metrics_by_category.values():\n",
    "            all_metrics.extend(cat_metrics)\n",
    "\n",
    "        # Taxonomy\n",
    "        taxonomy = self._detect_taxonomy(fields)\n",
    "\n",
    "        # Currency (global)\n",
    "        global_parts = [fields.title, fields.name, fields.tags,\n",
    "                        fields.notes, fields.methodology]\n",
    "        for r in fields.resources:\n",
    "            global_parts.append(r.get('name', ''))\n",
    "            global_parts.append(r.get('description', ''))\n",
    "        global_text = ' '.join(p for p in global_parts if p)\n",
    "        currency = self._detect_currency(global_text)\n",
    "\n",
    "        # Confidence\n",
    "        confidences = [c.confidence for c in categories]\n",
    "        confidences.extend([m.confidence for m in all_metrics])\n",
    "        overall_confidence = np.mean(confidences) if confidences else 0.0\n",
    "\n",
    "        extraction = ExposureExtraction(\n",
    "            categories=categories,\n",
    "            metrics=all_metrics,\n",
    "            taxonomy_hint=taxonomy,\n",
    "            overall_confidence=overall_confidence,\n",
    "        )\n",
    "        extraction._metrics_by_category = metrics_by_category\n",
    "        extraction._currency = currency\n",
    "        extraction._tier_info = {\n",
    "            'tier1_cats': list(tier1.keys()),\n",
    "            'tier2_cats': list(tier2.keys()),\n",
    "            'tier3_cats': list(tier3.keys()),\n",
    "        }\n",
    "\n",
    "        return extraction\n",
    "\n",
    "\n",
    "# Initialize\n",
    "exposure_extractor = ExposureExtractor(SIGNAL_DICT)\n",
    "print(f\"ExposureExtractor initialized (3-tier cascade).\")\n",
    "print(f\"  - Categories: {len(exposure_extractor.category_patterns)} \"\n",
    "      f\"({sorted(exposure_extractor.category_patterns.keys())})\")\n",
    "print(f\"  - Tier weights: T1={ExposureExtractor.TIER1_CONFIDENCE}, \"\n",
    "      f\"T2={ExposureExtractor.TIER2_CONFIDENCE}, \"\n",
    "      f\"T3={ExposureExtractor.TIER3_CONFIDENCE}\")\n",
    "print(f\"  - Corroboration boost: {ExposureExtractor.CORROBORATION_BOOST}\")\n",
    "print(f\"  - Dimension patterns: {len(exposure_extractor.dimension_patterns)} dimensions\")\n",
    "print(f\"  - Taxonomy patterns: {len(exposure_extractor.taxonomy_patterns)} schemes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RDLS Exposure Block Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exposure block builder defined with schema compliance:\n",
      "  - dimension values: lowercase only (Issue 1)\n",
      "  - no 'Other' dimension (Issue 2)\n",
      "  - per-category metrics (Issue 4)\n",
      "  - currency field when quantity_kind = monetary (Issue 6)\n",
      "  - all values validated against schema codelists\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "3.1 Build RDLS Exposure Block\n",
    "\n",
    "Generates schema-compliant RDLS v0.3 exposure array.\n",
    "Key compliance rules:\n",
    "- dimension values MUST be lowercase (schema metric_dimension enum)\n",
    "- currency field included when quantity_kind = monetary\n",
    "- Each exposure item gets category-specific metrics (not duplicated)\n",
    "- All values validated against schema codelists\n",
    "\"\"\"\n",
    "\n",
    "def build_exposure_block(\n",
    "    extraction: ExposureExtraction,\n",
    "    dataset_id: str\n",
    ") -> Optional[List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Build RDLS exposure block from extraction results.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    extraction : ExposureExtraction\n",
    "        Extraction results (with _metrics_by_category and _currency attached)\n",
    "    dataset_id : str\n",
    "        Dataset identifier for generating unique IDs\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Optional[List[Dict[str, Any]]]\n",
    "        RDLS exposure array or None if no categories detected\n",
    "    \"\"\"\n",
    "    if not extraction.categories:\n",
    "        return None\n",
    "    \n",
    "    # Get per-category metrics (attached by extractor)\n",
    "    metrics_by_category = getattr(extraction, '_metrics_by_category', {})\n",
    "    currency = getattr(extraction, '_currency', '')\n",
    "    \n",
    "    exposure_items = []\n",
    "    id_prefix = dataset_id[:8] if dataset_id else 'unknown'\n",
    "    \n",
    "    for i, cat in enumerate(extraction.categories):\n",
    "        category = cat.value\n",
    "        \n",
    "        # Validate category against schema\n",
    "        if category not in VALID_EXPOSURE_CATEGORIES:\n",
    "            continue\n",
    "        \n",
    "        exposure_item = {\n",
    "            'id': f\"exposure_{id_prefix}_{i+1}\",\n",
    "            'category': category,\n",
    "        }\n",
    "        \n",
    "        # Add taxonomy if detected\n",
    "        if extraction.taxonomy_hint and extraction.taxonomy_hint in VALID_TAXONOMIES:\n",
    "            exposure_item['taxonomy'] = extraction.taxonomy_hint\n",
    "        \n",
    "        # --- Build metrics for this specific category ---\n",
    "        cat_metrics = metrics_by_category.get(category, [])\n",
    "        \n",
    "        if cat_metrics:\n",
    "            metrics = []\n",
    "            for j, m in enumerate(cat_metrics):\n",
    "                # Validate and enforce lowercase dimension\n",
    "                dim = m.dimension.lower()\n",
    "                if dim not in VALID_METRIC_DIMENSIONS:\n",
    "                    # Fallback to category default\n",
    "                    dim = CATEGORY_DEFAULT_METRICS.get(category, ('content', 'count'))[0]\n",
    "                \n",
    "                metric = {\n",
    "                    'id': f\"metric_{id_prefix}_{i+1}_{j+1}\",\n",
    "                    'dimension': dim,\n",
    "                    'quantity_kind': m.quantity_kind,\n",
    "                }\n",
    "                \n",
    "                # Add currency when quantity_kind is monetary\n",
    "                if m.quantity_kind == 'monetary':\n",
    "                    # Try to extract currency from metric source_hint\n",
    "                    metric_currency = ''\n",
    "                    if hasattr(m, 'source_hint') and '_currency_' in m.source_hint:\n",
    "                        metric_currency = m.source_hint.split('_currency_')[-1]\n",
    "                    if not metric_currency:\n",
    "                        metric_currency = currency\n",
    "                    metric['currency'] = metric_currency\n",
    "                \n",
    "                metrics.append(metric)\n",
    "            exposure_item['metrics'] = metrics\n",
    "        else:\n",
    "            # Fallback: create default metric for this category\n",
    "            default_dim, default_qty = CATEGORY_DEFAULT_METRICS.get(\n",
    "                category, ('content', 'count')\n",
    "            )\n",
    "            metric = {\n",
    "                'id': f\"metric_{id_prefix}_{i+1}_1\",\n",
    "                'dimension': default_dim,\n",
    "                'quantity_kind': default_qty,\n",
    "            }\n",
    "            if default_qty == 'monetary':\n",
    "                metric['currency'] = currency\n",
    "            exposure_item['metrics'] = [metric]\n",
    "        \n",
    "        exposure_items.append(exposure_item)\n",
    "    \n",
    "    return exposure_items if exposure_items else None\n",
    "\n",
    "print(\"Exposure block builder defined with schema compliance:\")\n",
    "print(\"  - dimension values: lowercase only (Issue 1)\")\n",
    "print(\"  - no 'Other' dimension (Issue 2)\")\n",
    "print(\"  - per-category metrics (Issue 4)\")\n",
    "print(\"  - currency field when quantity_kind = monetary (Issue 6)\")\n",
    "print(\"  - all values validated against schema codelists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 34 unique sample records across 7 categories.\n",
      "\n",
      "Samples per expected category:\n",
      "  buildings: 5 samples\n",
      "  infrastructure: 6 samples\n",
      "  population: 5 samples\n",
      "  agriculture: 5 samples\n",
      "  natural_environment: 3 samples\n",
      "  economic_indicator: 5 samples\n",
      "  development_index: 5 samples\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "4.1 Load Comprehensive Sample Records for Testing\n",
    "\n",
    "Curated samples across all 7 RDLS exposure categories to test:\n",
    "- Issue 1: lowercase dimension values\n",
    "- Issue 2: No \"Other\" dimension\n",
    "- Issue 3: All 7 categories detected\n",
    "- Issue 4: Per-category metrics\n",
    "- Issue 5: Smart category-specific defaults\n",
    "- Issue 6: Currency detection for monetary metrics\n",
    "- Issue 7: Expanded taxonomy detection\n",
    "\"\"\"\n",
    "\n",
    "EXPOSURE_TEST_SAMPLES = {\n",
    "    'buildings': [\n",
    "        ('00a27905-efd2-4ce5-b5d2-6c862ad7d852__ai-building-footprint-in-izabal-guatemala.json',\n",
    "         'AI building footprints - structure/area metric expected'),\n",
    "        ('04c4bf06-511e-4009-9c03-4ec97334d944__hurricane-melissa-building-damage-assessment-in-jamaica.json',\n",
    "         'Building damage assessment - post-disaster, monetary possible'),\n",
    "        ('04c95b2c-7472-4516-80f7-b6ed950a5255__sri-lanka-floods-building-damage-assessment-in-colombo.json',\n",
    "         'Flood building damage - cross-category test (buildings + population)'),\n",
    "        ('01bb1f79-8e9f-4bb7-bc33-8693a7a3dd7c__hotosm-bgd-buildings.json',\n",
    "         'OSM building export - Bangladesh, structure/count'),\n",
    "        ('0453224c-92d5-4eed-a93c-5a465ef85883__hotosm-esp-buildings.json',\n",
    "         'OSM building export - Spain, structure/count'),\n",
    "    ],\n",
    "    'infrastructure': [\n",
    "        ('acf1231c-4248-4834-8e1f-e6d6939b0c6e__urban-transport-world.json',\n",
    "         'Urban transport accessibility - global SDG indicator'),\n",
    "        ('49c342a1-274f-4416-931a-c026841b128c__schools-in-syria-2019.json',\n",
    "         'Schools/facilities - infrastructure as health/education assets'),\n",
    "        ('7a565edc-67e7-4e12-ad9c-8c0756a558ed__world-bank-infrastructure-indicators-for-czech-republic.json',\n",
    "         'World Bank infrastructure indicators'),\n",
    "        ('fe9c7f0b-4024-4a2c-a98d-78ceee623497__hotosm-brb-roads.json',\n",
    "         'OSM roads - Barbados, structure/length metric expected'),\n",
    "        ('0bcaa7d8-84fd-4d7b-a831-25aaa6480167__world-bank-infrastructure-indicators-for-korea-dem-peoples-rep.json',\n",
    "         'World Bank infrastructure indicators - DPRK'),\n",
    "        ('dece59ba-c7c9-4c59-8481-abfcf059dddd__uganda-energy-gas-facilities.json',\n",
    "         'Energy/Gas facilities - tiered cascade regression test'),\n",
    "    ],\n",
    "    'population': [\n",
    "        ('6ffa577e-1f50-44a2-8f49-6b302e1da1a0__nepal-population-census-2011-cod.json',\n",
    "         'Nepal census - population/count, demographic data'),\n",
    "        ('60967843-7a89-4c4a-b76a-543bc0a4e2bc__saint-vincent-and-the-grenadines-gridded-population-dataset.json',\n",
    "         'Gridded population - spatial, area-based'),\n",
    "        ('1d7193a5-52ed-4e89-9d14-fb62f2ca8e9c__1999-2013-tally-of-internaly-displaced-persons-resulting-from-natural-disasters.json',\n",
    "         'Displaced persons tally - population/count'),\n",
    "        ('5ddc6df3-7d8d-438a-9867-70dbc04f91b4__spatialized-100m-school-age-population-grid-for-togo-by-educational-level-and-se.json',\n",
    "         'School-age population grid - 100m resolution'),\n",
    "        ('0a3aff95-e37e-48f4-844b-a105cd2325e8__dominica-gridded-population-dataset.json',\n",
    "         'Gridded population - Caribbean island'),\n",
    "    ],\n",
    "    'agriculture': [\n",
    "        ('80fafa94-f78f-4cfd-ad92-7cb4c7c2d7bc__horn-of-africa-food-security.json',\n",
    "         'Food security data - FEWSNET, multi-country'),\n",
    "        ('76654673-8c03-4431-a947-fd0fb853a70b__ethiopia-food-security.json',\n",
    "         'Ethiopia food security - product/area expected'),\n",
    "        ('1b9da567-1e83-40b0-9953-6f57c396a23c__guinea-food-security.json',\n",
    "         'Guinea food security'),\n",
    "        ('8aca8a6f-10a7-48e3-ae2c-807117303649__agricultural-and-food-production-index-indice-de-la-production-agricole-et-alime.json',\n",
    "         'Agricultural production index - product/count'),\n",
    "        ('7322e8fe-b7b4-4b3c-b445-a069ccb7f95e__african-development-bank-food-security-prices-monthly-december-2011.json',\n",
    "         'Food prices - may detect monetary/currency'),\n",
    "    ],\n",
    "    'natural_environment': [\n",
    "        ('00710e3e-c8ef-46c2-9cb0-d87070600bd7__geodata-of-landcover-classification-kalobeyei-turkana-county-kenya-july-01-2015.json',\n",
    "         'Land cover classification - content/area expected'),\n",
    "        ('342ad68f-501b-4f34-948e-a2d195018f95__world-bank-environment-indicators-for-czech-republic.json',\n",
    "         'Environment indicators - may overlap with index'),\n",
    "        ('31618b9d-0b3d-4ffd-9689-1b91ee80287b__world-bank-environment-indicators-for-turkey.json',\n",
    "         'Environment indicators - Turkey'),\n",
    "    ],\n",
    "    'economic_indicator': [\n",
    "        ('a3b57464-fa02-49c3-a8a0-3f26e12a7ebf__multi-hazard-average-annual-loss.json',\n",
    "         'Multi-hazard AAL - monetary/USD expected (Issue 6 test)'),\n",
    "        ('23efa9ad-5b20-43e1-bf2b-0c90226ff956__impact-data-casualties-and-damage-typhoon-haiyan-yolanda.json',\n",
    "         'Typhoon damage costs - monetary expected'),\n",
    "        ('290602c1-cd52-482f-b938-1af750e57bfe__world-bank-trade-indicators-for-turkey.json',\n",
    "         'Trade indicators - economic, monetary/USD'),\n",
    "        ('37894f3f-62ee-408f-9341-0572f2cea977__world-bank-financial-sector-indicators-for-czech-republic.json',\n",
    "         'Financial sector indicators'),\n",
    "        ('4fdcd4dc-5c2f-43af-a1e4-93c9b6539a27__wfp-food-prices.json',\n",
    "         'WFP food prices - currency detection test'),\n",
    "    ],\n",
    "    'development_index': [\n",
    "        ('0166def4-bac0-4d33-a929-f5596d18e178__indonesia-population-living-below-the-poverty-line-2007-2018.json',\n",
    "         'Poverty line data - development_index/count'),\n",
    "        ('0e5412f2-7c17-4ce9-8928-458865c5f7e9__education-index.json',\n",
    "         'Education index - index/count expected'),\n",
    "        ('9403e827-55cb-40d9-9d2b-192cf66f5726__indonesia-gender-empowerment-index-2010-2017.json',\n",
    "         'Gender empowerment index'),\n",
    "        ('2ab7d812-be62-48cb-bd94-407fd522e21e__kenya-health-spending-per-capita-per-county.json',\n",
    "         'Health spending per capita - development/monetary'),\n",
    "        ('03519575-043a-4414-92c4-203afe52b004__indicadores-del-sidih.json',\n",
    "         'SIDIH indicators - development indices'),\n",
    "    ],\n",
    "}\n",
    "\n",
    "# --- Load all samples ---\n",
    "sample_records = []\n",
    "sample_metadata = []\n",
    "loaded_ids = set()\n",
    "skipped = 0\n",
    "\n",
    "for expected_cat, samples in EXPOSURE_TEST_SAMPLES.items():\n",
    "    for filename, note in samples:\n",
    "        filepath = DATASET_METADATA_DIR / filename\n",
    "        if filepath.exists():\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                record = json.load(f)\n",
    "            rid = record.get('id', '')\n",
    "            if rid not in loaded_ids:\n",
    "                loaded_ids.add(rid)\n",
    "                sample_records.append(record)\n",
    "                sample_metadata.append({\n",
    "                    'expected_category': expected_cat,\n",
    "                    'note': note,\n",
    "                    'filename': filename,\n",
    "                })\n",
    "            else:\n",
    "                skipped += 1\n",
    "        else:\n",
    "            print(f\"  WARNING: Not found: {filename[:60]}...\")\n",
    "\n",
    "print(f\"Loaded {len(sample_records)} unique sample records across {len(EXPOSURE_TEST_SAMPLES)} categories.\")\n",
    "if skipped:\n",
    "    print(f\"  ({skipped} duplicates across categories)\")\n",
    "print(f\"\\nSamples per expected category:\")\n",
    "for cat, samples in EXPOSURE_TEST_SAMPLES.items():\n",
    "    print(f\"  {cat}: {len(samples)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "COMPREHENSIVE EXPOSURE EXTRACTION TEST RESULTS\n",
      "Testing 34 samples across 7 categories\n",
      "==========================================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [buildings] AI building footprint in Izabal, Guatemala\n",
      "  Note: AI building footprints - structure/area metric expected\n",
      "  Categories: buildings(1.0), infrastructure(0.9)\n",
      "  Metric [buildings]: dim=structure, qty=area (conf=0.8, for_buildings)\n",
      "  Metric [infrastructure]: dim=structure, qty=length (conf=0.5, for_infrastructure)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [buildings] Hurricane Melissa: Building Damage Assessment in Jamaica\n",
      "  Note: Building damage assessment - post-disaster, monetary possible\n",
      "  Categories: buildings(1.0)\n",
      "  Metric [buildings]: dim=structure, qty=count (conf=0.5, for_buildings)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [buildings] Sri Lanka Floods: Building Damage Assessment in Colombo\n",
      "  Note: Flood building damage - cross-category test (buildings + population)\n",
      "  Categories: buildings(1.0)\n",
      "  Metric [buildings]: dim=structure, qty=count (conf=0.5, for_buildings)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MISS] [buildings] Bangladesh Buildings (OpenStreetMap Export)\n",
      "  Note: OSM building export - Bangladesh, structure/count\n",
      "  Categories: infrastructure(1.0), economic_indicator(0.9)\n",
      "  Metric [infrastructure]: dim=structure, qty=length (conf=0.5, for_infrastructure)\n",
      "  Metric [economic_indicator]: dim=product, qty=monetary (conf=0.5, for_economic_indicator)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MISS] [buildings] Spain Buildings (OpenStreetMap Export)\n",
      "  Note: OSM building export - Spain, structure/count\n",
      "  Categories: infrastructure(1.0), economic_indicator(0.9)\n",
      "  Metric [infrastructure]: dim=structure, qty=length (conf=0.5, for_infrastructure)\n",
      "  Metric [economic_indicator]: dim=product, qty=monetary (conf=0.5, for_economic_indicator)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MISS] [infrastructure] Urban transport\n",
      "  Note: Urban transport accessibility - global SDG indicator\n",
      "  Categories: population(0.8)\n",
      "  Metric [population]: dim=population, qty=count (conf=0.5, for_population)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [infrastructure] Schools in Syria 2019 - Edition 5\n",
      "  Note: Schools/facilities - infrastructure as health/education assets\n",
      "  Categories: infrastructure(1.0)\n",
      "  Metric [infrastructure]: dim=structure, qty=length (conf=0.5, for_infrastructure)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [infrastructure] Czech Republic - Infrastructure\n",
      "  Note: World Bank infrastructure indicators\n",
      "  Categories: infrastructure(1.0)\n",
      "  Metric [infrastructure]: dim=structure, qty=length (conf=0.5, for_infrastructure)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MISS] [infrastructure] Barbados Roads (OpenStreetMap Export)\n",
      "  Note: OSM roads - Barbados, structure/length metric expected\n",
      "  Categories: economic_indicator(0.9)\n",
      "  Metric [economic_indicator]: dim=product, qty=monetary (conf=0.5, for_economic_indicator)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [infrastructure] Korea, Dem. People’s Rep. - Infrastructure\n",
      "  Note: World Bank infrastructure indicators - DPRK\n",
      "  Categories: infrastructure(1.0), population(1.0)\n",
      "  Metric [infrastructure]: dim=structure, qty=length (conf=0.5, for_infrastructure)\n",
      "  Metric [population]: dim=population, qty=count (conf=0.5, for_population)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [infrastructure] Uganda Energy/Gas Facilities\n",
      "  Note: Energy/Gas facilities - tiered cascade regression test\n",
      "  Categories: infrastructure(1.0)\n",
      "  Metric [infrastructure]: dim=structure, qty=length (conf=0.5, for_infrastructure)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [population] Nepal population census 2001\n",
      "  Note: Nepal census - population/count, demographic data\n",
      "  Categories: population(1.0)\n",
      "  Metric [population]: dim=population, qty=count (conf=0.5, for_population)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [population] Saint Vincent and the Grenadines Gridded Population Dataset\n",
      "  Note: Gridded population - spatial, area-based\n",
      "  Categories: population(1.0)\n",
      "  Metric [population]: dim=population, qty=count (conf=0.5, for_population)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [population] Kenya -  Tally of Internaly displaced persons resulting from natural disast\n",
      "  Note: Displaced persons tally - population/count\n",
      "  Categories: population(1.0), natural_environment(0.6)\n",
      "  Metric [population]: dim=population, qty=count (conf=0.5, for_population)\n",
      "  Metric [natural_environment]: dim=structure, qty=area (conf=0.5, for_natural_environment)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [population] Spatialized 100m school age population grid for Togo, by educational level \n",
      "  Note: School-age population grid - 100m resolution\n",
      "  Categories: infrastructure(1.0), population(1.0)\n",
      "  Metric [infrastructure]: dim=structure, qty=length (conf=0.5, for_infrastructure)\n",
      "  Metric [population]: dim=population, qty=count (conf=0.5, for_population)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [population] Dominica Gridded Population Dataset\n",
      "  Note: Gridded population - Caribbean island\n",
      "  Categories: population(1.0)\n",
      "  Metric [population]: dim=population, qty=count (conf=0.5, for_population)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [agriculture] Food Security for the Horn of Africa\n",
      "  Note: Food security data - FEWSNET, multi-country\n",
      "  Categories: agriculture(1.0)\n",
      "  Metric [agriculture]: dim=structure, qty=area (conf=0.5, for_agriculture)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [agriculture] Food Security for the Horn of Africa\n",
      "  Note: Ethiopia food security - product/area expected\n",
      "  Categories: agriculture(1.0)\n",
      "  Metric [agriculture]: dim=structure, qty=area (conf=0.5, for_agriculture)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [agriculture] Guinea - Food Security\n",
      "  Note: Guinea food security\n",
      "  Categories: agriculture(0.9)\n",
      "  Metric [agriculture]: dim=structure, qty=area (conf=0.5, for_agriculture)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [agriculture] Agricultural and Food Production Index – Indice de la production agricole e\n",
      "  Note: Agricultural production index - product/count\n",
      "  Categories: population(0.9), agriculture(1.0)\n",
      "  Metric [population]: dim=population, qty=count (conf=0.5, for_population)\n",
      "  Metric [agriculture]: dim=product, qty=monetary (conf=0.5, for_agriculture)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [agriculture] African Development Bank, Food Security, Prices, Monthly, December 2011\n",
      "  Note: Food prices - may detect monetary/currency\n",
      "  Categories: agriculture(1.0)\n",
      "  Metric [agriculture]: dim=product, qty=monetary (conf=0.5, for_agriculture)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [natural_environment] Geodata of Landcover Classification, Kalobeyei, Turkana County, Kenya\n",
      "  Note: Land cover classification - content/area expected\n",
      "  Categories: natural_environment(0.8)\n",
      "  Metric [natural_environment]: dim=structure, qty=area (conf=0.5, for_natural_environment)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [natural_environment] Czech Republic - Environment\n",
      "  Note: Environment indicators - may overlap with index\n",
      "  Categories: infrastructure(0.8), population(0.8), agriculture(0.8), natural_environment(0.6)\n",
      "  Metric [infrastructure]: dim=structure, qty=length (conf=0.5, for_infrastructure)\n",
      "  Metric [population]: dim=population, qty=count (conf=0.5, for_population)\n",
      "  Metric [agriculture]: dim=structure, qty=area (conf=0.5, for_agriculture)\n",
      "  Metric [natural_environment]: dim=structure, qty=area (conf=0.5, for_natural_environment)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [natural_environment] Turkey - Environment\n",
      "  Note: Environment indicators - Turkey\n",
      "  Categories: infrastructure(0.8), population(0.8), agriculture(0.8), natural_environment(0.6)\n",
      "  Metric [infrastructure]: dim=structure, qty=length (conf=0.5, for_infrastructure)\n",
      "  Metric [population]: dim=population, qty=count (conf=0.5, for_population)\n",
      "  Metric [agriculture]: dim=structure, qty=area (conf=0.5, for_agriculture)\n",
      "  Metric [natural_environment]: dim=structure, qty=area (conf=0.5, for_natural_environment)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MISS] [economic_indicator] Multi-hazard Average Annual Loss\n",
      "  Note: Multi-hazard AAL - monetary/USD expected (Issue 6 test)\n",
      "  Categories: buildings(0.5), infrastructure(0.5)\n",
      "  Metric [buildings]: dim=structure, qty=area (conf=0.8, for_buildings)\n",
      "  Metric [infrastructure]: dim=structure, qty=length (conf=0.5, for_infrastructure)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MISS] [economic_indicator] Impact data - casualties and damage - Typhoon Haiyan (Yolanda)\n",
      "  Note: Typhoon damage costs - monetary expected\n",
      "  Categories: None detected\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [economic_indicator] Turkey - Trade\n",
      "  Note: Trade indicators - economic, monetary/USD\n",
      "  Categories: economic_indicator(1.0), agriculture(0.8)\n",
      "  Metric [economic_indicator]: dim=product, qty=monetary (conf=0.5, for_economic_indicator)\n",
      "  Metric [agriculture]: dim=structure, qty=area (conf=0.5, for_agriculture)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [economic_indicator] Czech Republic - Financial Sector\n",
      "  Note: Financial sector indicators\n",
      "  Categories: population(0.8), economic_indicator(0.8)\n",
      "  Metric [population]: dim=population, qty=count (conf=0.5, for_population)\n",
      "  Metric [economic_indicator]: dim=product, qty=monetary (conf=0.5, for_economic_indicator_currency_USD)\n",
      "  Currency: USD\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MISS] [economic_indicator] Global Food Prices Database (WFP)\n",
      "  Note: WFP food prices - currency detection test\n",
      "  Categories: None detected\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MATCH] [development_index] Indonesia Population living below the poverty line, 2007-2020\n",
      "  Note: Poverty line data - development_index/count\n",
      "  Categories: population(1.0), development_index(1.0)\n",
      "  Metric [population]: dim=population, qty=count (conf=0.5, for_population)\n",
      "  Metric [development_index]: dim=index, qty=count (conf=0.5, for_development_index)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MISS] [development_index] UNDP Human Development Reports: Education Index\n",
      "  Note: Education index - index/count expected\n",
      "  Categories: None detected\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MISS] [development_index] Indonesia Gender Empowerment Index, 2010-2017\n",
      "  Note: Gender empowerment index\n",
      "  Categories: None detected\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MISS] [development_index] Kenya -  Expenditure on Malaria Per capita per county\n",
      "  Note: Health spending per capita - development/monetary\n",
      "  Categories: None detected\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[MISS] [development_index] Indicadores del SIDIH\n",
      "  Note: SIDIH indicators - development indices\n",
      "  Categories: None detected\n",
      "\n",
      "==========================================================================================\n",
      "EXTRACTION SUMMARY BY CATEGORY\n",
      "==========================================================================================\n",
      "  buildings              [###..] 3/5 detected\n",
      "  infrastructure         [####..] 4/6 detected\n",
      "  population             [#####] 5/5 detected\n",
      "  agriculture            [#####] 5/5 detected\n",
      "  natural_environment    [###] 3/3 detected\n",
      "  economic_indicator     [##...] 2/5 detected\n",
      "  development_index      [#....] 1/5 detected\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "4.2 Run Extraction and Validate All 7 Issues\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"COMPREHENSIVE EXPOSURE EXTRACTION TEST RESULTS\")\n",
    "print(f\"Testing {len(sample_records)} samples across {len(EXPOSURE_TEST_SAMPLES)} categories\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "extraction_results = []\n",
    "\n",
    "for i, (record, meta) in enumerate(zip(sample_records, sample_metadata)):\n",
    "    extraction = exposure_extractor.extract(record)\n",
    "    \n",
    "    result = {\n",
    "        'id': record.get('id'),\n",
    "        'title': record.get('title', '')[:70],\n",
    "        'record': record,\n",
    "        'extraction': extraction,\n",
    "        'expected_category': meta['expected_category'],\n",
    "        'note': meta['note'],\n",
    "    }\n",
    "    extraction_results.append(result)\n",
    "    \n",
    "    # Check if expected category was detected\n",
    "    detected_cats = [c.value for c in extraction.categories]\n",
    "    expected_found = meta['expected_category'] in detected_cats\n",
    "    status = \"MATCH\" if expected_found else \"MISS\"\n",
    "    \n",
    "    print(f\"\\n{'â”€' * 90}\")\n",
    "    print(f\"[{status}] [{meta['expected_category']}] {record.get('title', '')[:75]}\")\n",
    "    print(f\"  Note: {meta['note']}\")\n",
    "    \n",
    "    if extraction.categories:\n",
    "        cats_str = ', '.join(f\"{c.value}({c.confidence:.1f})\" for c in extraction.categories)\n",
    "        print(f\"  Categories: {cats_str}\")\n",
    "    else:\n",
    "        print(f\"  Categories: None detected\")\n",
    "    \n",
    "    # Show per-category metrics\n",
    "    metrics_by_cat = getattr(extraction, '_metrics_by_category', {})\n",
    "    if metrics_by_cat:\n",
    "        for cat, metrics in metrics_by_cat.items():\n",
    "            for m in metrics:\n",
    "                print(f\"  Metric [{cat}]: dim={m.dimension}, qty={m.quantity_kind} \"\n",
    "                      f\"(conf={m.confidence:.1f}, {m.source_hint})\")\n",
    "    \n",
    "    currency = getattr(extraction, '_currency', '')\n",
    "    if currency:\n",
    "        print(f\"  Currency: {currency}\")\n",
    "    if extraction.taxonomy_hint:\n",
    "        print(f\"  Taxonomy: {extraction.taxonomy_hint}\")\n",
    "\n",
    "# --- Summary ---\n",
    "print(f\"\\n{'=' * 90}\")\n",
    "print(\"EXTRACTION SUMMARY BY CATEGORY\")\n",
    "print(f\"{'=' * 90}\")\n",
    "\n",
    "for expected_cat in EXPOSURE_TEST_SAMPLES:\n",
    "    cat_results = [r for r in extraction_results if r['expected_category'] == expected_cat]\n",
    "    detected = sum(1 for r in cat_results\n",
    "                   if expected_cat in [c.value for c in r['extraction'].categories])\n",
    "    total = len(cat_results)\n",
    "    \n",
    "    bar = \"#\" * detected + \".\" * (total - detected)\n",
    "    print(f\"  {expected_cat:22s} [{bar}] {detected}/{total} detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "RDLS EXPOSURE BLOCK STRUCTURAL VERIFICATION\n",
      "==========================================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[buildings] AI building footprint in Izabal, Guatemala\n",
      "  exposure_00a27905_1: category=buildings\n",
      "    metric_00a27905_1_1: dim=structure, qty=area\n",
      "  exposure_00a27905_2: category=infrastructure\n",
      "    metric_00a27905_2_1: dim=structure, qty=length\n",
      "\n",
      "  Full JSON preview:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"exposure_00a27905_1\",\n",
      "    \"category\": \"buildings\",\n",
      "    \"metrics\": [\n",
      "      {\n",
      "        \"id\": \"metric_00a27905_1_1\",\n",
      "        \"dimension\": \"structure\",\n",
      "        \"quantity_kind\": \"area\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"exposure_00a27905_2\",\n",
      "    \"category\": \"infrastructure\",\n",
      "    \"metrics\": [\n",
      "      {\n",
      "        \"id\": \"metric_00a27905_2_1\",\n",
      "        \"dimension\": \"structure\",\n",
      "        \"quantity_kind\": \"length\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[buildings] Hurricane Melissa: Building Damage Assessment in Jamaica\n",
      "  exposure_04c4bf06_1: category=buildings\n",
      "    metric_04c4bf06_1_1: dim=structure, qty=count\n",
      "\n",
      "  Full JSON preview:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"exposure_04c4bf06_1\",\n",
      "    \"category\": \"buildings\",\n",
      "    \"metrics\": [\n",
      "      {\n",
      "        \"id\": \"metric_04c4bf06_1_1\",\n",
      "        \"dimension\": \"structure\",\n",
      "        \"quantity_kind\": \"count\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[buildings] Sri Lanka Floods: Building Damage Assessment in Colombo\n",
      "  exposure_04c95b2c_1: category=buildings\n",
      "    metric_04c95b2c_1_1: dim=structure, qty=count\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[buildings] Bangladesh Buildings (OpenStreetMap Export)\n",
      "  exposure_01bb1f79_1: category=infrastructure\n",
      "    metric_01bb1f79_1_1: dim=structure, qty=length\n",
      "  exposure_01bb1f79_2: category=economic_indicator\n",
      "    metric_01bb1f79_2_1: dim=product, qty=monetary, currency=\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[buildings] Spain Buildings (OpenStreetMap Export)\n",
      "  exposure_0453224c_1: category=infrastructure\n",
      "    metric_0453224c_1_1: dim=structure, qty=length\n",
      "  exposure_0453224c_2: category=economic_indicator\n",
      "    metric_0453224c_2_1: dim=product, qty=monetary, currency=\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[infrastructure] Urban transport\n",
      "  exposure_acf1231c_1: category=population\n",
      "    metric_acf1231c_1_1: dim=population, qty=count\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[infrastructure] Schools in Syria 2019 - Edition 5\n",
      "  exposure_49c342a1_1: category=infrastructure\n",
      "    metric_49c342a1_1_1: dim=structure, qty=length\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[infrastructure] Czech Republic - Infrastructure\n",
      "  exposure_7a565edc_1: category=infrastructure\n",
      "    metric_7a565edc_1_1: dim=structure, qty=length\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[infrastructure] Barbados Roads (OpenStreetMap Export)\n",
      "  exposure_fe9c7f0b_1: category=economic_indicator\n",
      "    metric_fe9c7f0b_1_1: dim=product, qty=monetary, currency=\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[infrastructure] Korea, Dem. People’s Rep. - Infrastructure\n",
      "  exposure_0bcaa7d8_1: category=infrastructure\n",
      "    metric_0bcaa7d8_1_1: dim=structure, qty=length\n",
      "  exposure_0bcaa7d8_2: category=population\n",
      "    metric_0bcaa7d8_2_1: dim=population, qty=count\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[infrastructure] Uganda Energy/Gas Facilities\n",
      "  exposure_dece59ba_1: category=infrastructure\n",
      "    metric_dece59ba_1_1: dim=structure, qty=length\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[population] Nepal population census 2001\n",
      "  exposure_6ffa577e_1: category=population\n",
      "    metric_6ffa577e_1_1: dim=population, qty=count\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[population] Saint Vincent and the Grenadines Gridded Population Dataset\n",
      "  exposure_60967843_1: category=population\n",
      "    metric_60967843_1_1: dim=population, qty=count\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[population] Kenya -  Tally of Internaly displaced persons resulting from natural d\n",
      "  exposure_1d7193a5_1: category=population\n",
      "    metric_1d7193a5_1_1: dim=population, qty=count\n",
      "  exposure_1d7193a5_2: category=natural_environment\n",
      "    metric_1d7193a5_2_1: dim=structure, qty=area\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[population] Spatialized 100m school age population grid for Togo, by educational l\n",
      "  exposure_5ddc6df3_1: category=infrastructure\n",
      "    metric_5ddc6df3_1_1: dim=structure, qty=length\n",
      "  exposure_5ddc6df3_2: category=population\n",
      "    metric_5ddc6df3_2_1: dim=population, qty=count\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[population] Dominica Gridded Population Dataset\n",
      "  exposure_0a3aff95_1: category=population\n",
      "    metric_0a3aff95_1_1: dim=population, qty=count\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[agriculture] Food Security for the Horn of Africa\n",
      "  exposure_80fafa94_1: category=agriculture\n",
      "    metric_80fafa94_1_1: dim=structure, qty=area\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[agriculture] Food Security for the Horn of Africa\n",
      "  exposure_76654673_1: category=agriculture\n",
      "    metric_76654673_1_1: dim=structure, qty=area\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[agriculture] Guinea - Food Security\n",
      "  exposure_1b9da567_1: category=agriculture\n",
      "    metric_1b9da567_1_1: dim=structure, qty=area\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[agriculture] Agricultural and Food Production Index – Indice de la production agric\n",
      "  exposure_8aca8a6f_1: category=population\n",
      "    metric_8aca8a6f_1_1: dim=population, qty=count\n",
      "  exposure_8aca8a6f_2: category=agriculture\n",
      "    metric_8aca8a6f_2_1: dim=product, qty=monetary, currency=\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[agriculture] African Development Bank, Food Security, Prices, Monthly, December 201\n",
      "  exposure_7322e8fe_1: category=agriculture\n",
      "    metric_7322e8fe_1_1: dim=product, qty=monetary, currency=\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[natural_environment] Geodata of Landcover Classification, Kalobeyei, Turkana County, Kenya\n",
      "  exposure_00710e3e_1: category=natural_environment\n",
      "    metric_00710e3e_1_1: dim=structure, qty=area\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[natural_environment] Czech Republic - Environment\n",
      "  exposure_342ad68f_1: category=infrastructure\n",
      "    metric_342ad68f_1_1: dim=structure, qty=length\n",
      "  exposure_342ad68f_2: category=population\n",
      "    metric_342ad68f_2_1: dim=population, qty=count\n",
      "  exposure_342ad68f_3: category=agriculture\n",
      "    metric_342ad68f_3_1: dim=structure, qty=area\n",
      "  exposure_342ad68f_4: category=natural_environment\n",
      "    metric_342ad68f_4_1: dim=structure, qty=area\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[natural_environment] Turkey - Environment\n",
      "  exposure_31618b9d_1: category=infrastructure\n",
      "    metric_31618b9d_1_1: dim=structure, qty=length\n",
      "  exposure_31618b9d_2: category=population\n",
      "    metric_31618b9d_2_1: dim=population, qty=count\n",
      "  exposure_31618b9d_3: category=agriculture\n",
      "    metric_31618b9d_3_1: dim=structure, qty=area\n",
      "  exposure_31618b9d_4: category=natural_environment\n",
      "    metric_31618b9d_4_1: dim=structure, qty=area\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[economic_indicator] Multi-hazard Average Annual Loss\n",
      "  exposure_a3b57464_1: category=buildings\n",
      "    metric_a3b57464_1_1: dim=structure, qty=area\n",
      "  exposure_a3b57464_2: category=infrastructure\n",
      "    metric_a3b57464_2_1: dim=structure, qty=length\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[economic_indicator] Turkey - Trade\n",
      "  exposure_290602c1_1: category=economic_indicator\n",
      "    metric_290602c1_1_1: dim=product, qty=monetary, currency=\n",
      "  exposure_290602c1_2: category=agriculture\n",
      "    metric_290602c1_2_1: dim=structure, qty=area\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[economic_indicator] Czech Republic - Financial Sector\n",
      "  exposure_37894f3f_1: category=population\n",
      "    metric_37894f3f_1_1: dim=population, qty=count\n",
      "  exposure_37894f3f_2: category=economic_indicator\n",
      "    metric_37894f3f_2_1: dim=product, qty=monetary, currency=USD\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[development_index] Indonesia Population living below the poverty line, 2007-2020\n",
      "  exposure_0166def4_1: category=population\n",
      "    metric_0166def4_1_1: dim=population, qty=count\n",
      "  exposure_0166def4_2: category=development_index\n",
      "    metric_0166def4_2_1: dim=index, qty=count\n",
      "\n",
      "==========================================================================================\n",
      "STRUCTURAL COMPLIANCE REPORT\n",
      "==========================================================================================\n",
      "  Total exposure blocks built:        28\n",
      "  Total exposure items:               45\n",
      "  Total metrics:                      45\n",
      "  Unique categories detected:         ['agriculture', 'buildings', 'development_index', 'economic_indicator', 'infrastructure', 'natural_environment', 'population']\n",
      "\n",
      "  Issue 1 - Lowercase dimensions:     PASS\n",
      "  Issue 2 - No 'Other' dimension:     PASS\n",
      "  Issue 3 - All valid dimensions:     PASS\n",
      "  Issue 4 - Categories detected:      7/7 (['agriculture', 'buildings', 'development_index', 'economic_indicator', 'infrastructure', 'natural_environment', 'population'])\n",
      "  Issue 6 - Monetary with currency:   7 (without: 0)\n",
      "  Missing categories:                 none\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "4.3 Build Exposure Blocks and Verify Structural Compliance\n",
    "\n",
    "Verifies all 7 issues are fixed in the generated RDLS exposure blocks.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"RDLS EXPOSURE BLOCK STRUCTURAL VERIFICATION\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Compliance counters\n",
    "total_blocks = 0\n",
    "total_items = 0\n",
    "total_metrics = 0\n",
    "uppercase_dims = 0\n",
    "invalid_dims = 0\n",
    "other_dims = 0\n",
    "monetary_with_currency = 0\n",
    "monetary_without_currency = 0\n",
    "categories_seen = set()\n",
    "\n",
    "for result in extraction_results:\n",
    "    if not result['extraction'].categories:\n",
    "        continue\n",
    "    \n",
    "    exposure_block = build_exposure_block(\n",
    "        result['extraction'],\n",
    "        result['id']\n",
    "    )\n",
    "    if not exposure_block:\n",
    "        continue\n",
    "    \n",
    "    total_blocks += 1\n",
    "    \n",
    "    print(f\"\\n{'â”€' * 90}\")\n",
    "    print(f\"[{result['expected_category']}] {result['title']}\")\n",
    "    \n",
    "    for item in exposure_block:\n",
    "        total_items += 1\n",
    "        categories_seen.add(item['category'])\n",
    "        \n",
    "        taxonomy_str = f\", taxonomy={item.get('taxonomy', '-')}\" if 'taxonomy' in item else \"\"\n",
    "        print(f\"  {item['id']}: category={item['category']}{taxonomy_str}\")\n",
    "        \n",
    "        for metric in item['metrics']:\n",
    "            total_metrics += 1\n",
    "            dim = metric['dimension']\n",
    "            qty = metric['quantity_kind']\n",
    "            currency_str = f\", currency={metric.get('currency', '')}\" if 'currency' in metric else \"\"\n",
    "            \n",
    "            # Check compliance\n",
    "            if dim != dim.lower():\n",
    "                uppercase_dims += 1\n",
    "            if dim.lower() not in VALID_METRIC_DIMENSIONS:\n",
    "                invalid_dims += 1\n",
    "            if dim.lower() == 'other':\n",
    "                other_dims += 1\n",
    "            if qty == 'monetary':\n",
    "                if 'currency' in metric:\n",
    "                    monetary_with_currency += 1\n",
    "                else:\n",
    "                    monetary_without_currency += 1\n",
    "            \n",
    "            print(f\"    {metric['id']}: dim={dim}, qty={qty}{currency_str}\")\n",
    "    \n",
    "    # Show full JSON for first 2 blocks\n",
    "    if total_blocks <= 2:\n",
    "        print(f\"\\n  Full JSON preview:\")\n",
    "        print(json.dumps(exposure_block, indent=2)[:1500])\n",
    "\n",
    "# --- Final compliance report ---\n",
    "print(f\"\\n{'=' * 90}\")\n",
    "print(\"STRUCTURAL COMPLIANCE REPORT\")\n",
    "print(f\"{'=' * 90}\")\n",
    "print(f\"  Total exposure blocks built:        {total_blocks}\")\n",
    "print(f\"  Total exposure items:               {total_items}\")\n",
    "print(f\"  Total metrics:                      {total_metrics}\")\n",
    "print(f\"  Unique categories detected:         {sorted(categories_seen)}\")\n",
    "print(f\"\")\n",
    "print(f\"  Issue 1 - Lowercase dimensions:     {'PASS' if uppercase_dims == 0 else f'FAIL ({uppercase_dims} uppercase)'}\")\n",
    "print(f\"  Issue 2 - No 'Other' dimension:     {'PASS' if other_dims == 0 else f'FAIL ({other_dims} found)'}\")\n",
    "print(f\"  Issue 3 - All valid dimensions:     {'PASS' if invalid_dims == 0 else f'FAIL ({invalid_dims} invalid)'}\")\n",
    "print(f\"  Issue 4 - Categories detected:      {len(categories_seen)}/7 ({sorted(categories_seen)})\")\n",
    "print(f\"  Issue 6 - Monetary with currency:   {monetary_with_currency} (without: {monetary_without_currency})\")\n",
    "print(f\"  Missing categories:                 {VALID_EXPOSURE_CATEGORIES - categories_seen or 'none'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all records...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3182406885d74c0484e823c52fd58b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting:   0%|          | 0/26246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "5.1 Process All Records\n",
    "\"\"\"\n",
    "\n",
    "def process_exposure_extraction(\n",
    "    metadata_dir: Path,\n",
    "    extractor: ExposureExtractor,\n",
    "    limit: Optional[int] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process all HDX records for exposure extraction.\n",
    "    \"\"\"\n",
    "    json_files = list(metadata_dir.glob('*.json'))\n",
    "    if limit:\n",
    "        json_files = json_files[:limit]\n",
    "    \n",
    "    results = []\n",
    "    iterator = tqdm(json_files, desc=\"Extracting\") if HAS_TQDM else json_files\n",
    "    \n",
    "    for filepath in iterator:\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                record = json.load(f)\n",
    "            \n",
    "            extraction = extractor.extract(record)\n",
    "            \n",
    "            results.append({\n",
    "                'id': record.get('id'),\n",
    "                'title': record.get('title'),\n",
    "                'organization': record.get('organization'),\n",
    "                'categories': [c.value for c in extraction.categories],\n",
    "                'category_count': len(extraction.categories),\n",
    "                'has_exposure': len(extraction.categories) > 0,\n",
    "                'taxonomy': extraction.taxonomy_hint,\n",
    "                'overall_confidence': extraction.overall_confidence,\n",
    "                'extraction': extraction\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            results.append({'id': filepath.stem, 'error': str(e)})\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Process\n",
    "PROCESS_LIMIT = None  # Set to None for full corpus\n",
    "\n",
    "print(f\"Processing {PROCESS_LIMIT or 'all'} records...\")\n",
    "df_exposure = process_exposure_extraction(DATASET_METADATA_DIR, exposure_extractor, limit=PROCESS_LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPOSURE EXTRACTION STATISTICS\n",
      "============================================================\n",
      "\n",
      "Total records: 26,246\n",
      "With exposure signals: 21,717 (82.7%)\n",
      "\n",
      "Category Distribution:\n",
      "  population: 12760\n",
      "  infrastructure: 8647\n",
      "  economic_indicator: 6577\n",
      "  agriculture: 5041\n",
      "  natural_environment: 2746\n",
      "  buildings: 1562\n",
      "  development_index: 1248\n",
      "\n",
      "Confidence (exposure records):\n",
      "  Mean: 0.67\n",
      "  High (>=0.8): 254\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "5.2 Extraction Statistics\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPOSURE EXTRACTION STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total = len(df_exposure)\n",
    "with_exposure = df_exposure['has_exposure'].sum()\n",
    "\n",
    "print(f\"\\nTotal records: {total:,}\")\n",
    "print(f\"With exposure signals: {with_exposure:,} ({with_exposure/total*100:.1f}%)\")\n",
    "\n",
    "# Category distribution\n",
    "cat_counts = Counter()\n",
    "for cats in df_exposure['categories'].dropna():\n",
    "    cat_counts.update(cats)\n",
    "\n",
    "print(f\"\\nCategory Distribution:\")\n",
    "for cat, count in cat_counts.most_common():\n",
    "    print(f\"  {cat}: {count}\")\n",
    "\n",
    "# Confidence distribution\n",
    "conf = df_exposure[df_exposure['has_exposure']]['overall_confidence']\n",
    "print(f\"\\nConfidence (exposure records):\")\n",
    "print(f\"  Mean: {conf.mean():.2f}\")\n",
    "print(f\"  High (>=0.8): {(conf >= 0.8).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output cleanup [NB 10 Exposure Extraction]:\n",
      "  rdls_exp-hdx_*.json                     : 20,892 files\n",
      "  exposure_extraction_results.csv         : 1 files\n",
      "  exposure_extraction_high_confidence.csv : 1 files\n",
      "  Cleaned 20,894 files. Ready for fresh output.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'deleted': 20894, 'skipped': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "6.0 Clean Previous Outputs\n",
    "\n",
    "Removes stale output files before writing new ones.\n",
    "Controlled by CLEANUP_MODE in cell 1.2 above.\n",
    "\"\"\"\n",
    "\n",
    "def clean_previous_outputs(output_dir, patterns, label, mode=\"replace\"):\n",
    "    \"\"\"\n",
    "    Remove previous output files matching the given glob patterns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    output_dir : Path\n",
    "        Directory containing old outputs.\n",
    "    patterns : list[str]\n",
    "        Glob patterns to match.\n",
    "    label : str\n",
    "        Human-readable label for log messages.\n",
    "    mode : str\n",
    "        One of: \"replace\" (auto-delete), \"prompt\" (ask user),\n",
    "        \"skip\" (keep old files), \"abort\" (error if stale files exist).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict  with keys 'deleted' (int) and 'skipped' (bool)\n",
    "    \"\"\"\n",
    "    result = {'deleted': 0, 'skipped': False}\n",
    "    targets = {}\n",
    "    for pattern in patterns:\n",
    "        matches = sorted(output_dir.glob(pattern))\n",
    "        if matches:\n",
    "            targets[pattern] = matches\n",
    "    total = sum(len(files) for files in targets.values())\n",
    "\n",
    "    if total == 0:\n",
    "        print(f'Output cleanup [{label}]: Directory is clean.')\n",
    "        return result\n",
    "\n",
    "    summary = []\n",
    "    for pattern, files in targets.items():\n",
    "        summary.append(f'  {pattern:40s}: {len(files):,} files')\n",
    "\n",
    "    if mode == 'skip':\n",
    "        print(f'Output cleanup [{label}]: SKIPPED ({total:,} existing files kept)')\n",
    "        result['skipped'] = True\n",
    "        return result\n",
    "\n",
    "    if mode == 'abort':\n",
    "        raise RuntimeError(\n",
    "            f'Output cleanup [{label}]: ABORT -- {total:,} stale files found. '\n",
    "            f'Delete manually or change CLEANUP_MODE.'\n",
    "        )\n",
    "\n",
    "    if mode == 'prompt':\n",
    "        print(f'Output cleanup [{label}]: Found {total:,} existing output files:')\n",
    "        for line in summary:\n",
    "            print(line)\n",
    "        choice = input('Choose [R]eplace / [S]kip / [A]bort: ').strip().lower()\n",
    "        if choice in ('s', 'skip'):\n",
    "            print('  Skipped.')\n",
    "            result['skipped'] = True\n",
    "            return result\n",
    "        elif choice in ('a', 'abort'):\n",
    "            raise RuntimeError('User chose to abort.')\n",
    "        elif choice not in ('r', 'replace', ''):\n",
    "            print(f'  Unknown choice \"{choice}\", defaulting to Replace.')\n",
    "\n",
    "    # Mode: replace (default)\n",
    "    print(f'Output cleanup [{label}]:')\n",
    "    for line in summary:\n",
    "        print(line)\n",
    "    for pattern, files in targets.items():\n",
    "        for f in files:\n",
    "            try:\n",
    "                f.unlink()\n",
    "                result['deleted'] += 1\n",
    "            except Exception as e:\n",
    "                print(f'  WARNING: Could not delete {f.name}: {e}')\n",
    "    deleted_count = result['deleted']\n",
    "    print(f'  Cleaned {deleted_count:,} files. Ready for fresh output.')\n",
    "    print()\n",
    "    return result\n",
    "\n",
    "\n",
    "# -- Run cleanup for NB 10 Exposure Extraction outputs --\n",
    "clean_previous_outputs(\n",
    "    OUTPUT_DIR,\n",
    "    patterns=[\n",
    "        \"rdls_exp-hdx_*.json\",\n",
    "        \"exposure_extraction_results.csv\",\n",
    "        \"exposure_extraction_high_confidence.csv\",\n",
    "    ],\n",
    "    label=\"NB 10 Exposure Extraction\",\n",
    "    mode=CLEANUP_MODE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/extracted/exposure_extraction_results.csv\n",
      "Saved: /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/extracted/exposure_extraction_high_confidence.csv (254 records)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "6.1 Export Extraction Results\n",
    "\"\"\"\n",
    "\n",
    "# Prepare export\n",
    "export_df = df_exposure[[\n",
    "    'id', 'title', 'organization', 'categories', 'category_count',\n",
    "    'taxonomy', 'overall_confidence', 'has_exposure'\n",
    "]].copy()\n",
    "\n",
    "export_df['categories'] = export_df['categories'].apply(\n",
    "    lambda x: '|'.join(x) if isinstance(x, list) else ''\n",
    ")\n",
    "\n",
    "output_file = OUTPUT_DIR / 'exposure_extraction_results.csv'\n",
    "export_df.to_csv(output_file, index=False)\n",
    "print(f\"Saved: {output_file}\")\n",
    "\n",
    "# High confidence\n",
    "high_conf = export_df[export_df['has_exposure'] & (df_exposure['overall_confidence'] >= 0.8)]\n",
    "high_conf_file = OUTPUT_DIR / 'exposure_extraction_high_confidence.csv'\n",
    "high_conf.to_csv(high_conf_file, index=False)\n",
    "print(f\"Saved: {high_conf_file} ({len(high_conf)} records)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating RDLS exposure block JSONs for 20,530 datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f178248adf42e08876d8bf3d62a653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building exposure JSONs:   0%|          | 0/20530 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done.\n",
      "  Generated: 20,530 exposure block JSONs\n",
      "  Skipped (no valid block): 0\n",
      "  Output: /mnt/c/Users/benny/OneDrive/Documents/Github/hdx-metadata-crawler/hdx_dataset_metadata_dump/rdls/extracted\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "6.2 Generate RDLS Exposure Block JSONs for All Flagged Datasets\n",
    "\n",
    "Create RDLS JSON records with exposure blocks for ALL datasets\n",
    "where exposure was detected (not just a sample).\n",
    "These JSONs are consumed by NB 12 for HEVL integration.\n",
    "\"\"\"\n",
    "\n",
    "# Select ALL records with exposure detection\n",
    "all_exposure = df_exposure[\n",
    "    df_exposure['has_exposure'] &\n",
    "    (df_exposure['overall_confidence'] >= 0.5)\n",
    "].copy()\n",
    "\n",
    "print(f\"Generating RDLS exposure block JSONs for {len(all_exposure):,} datasets...\")\n",
    "\n",
    "generated = 0\n",
    "skipped = 0\n",
    "\n",
    "iterator = tqdm(all_exposure.iterrows(), total=len(all_exposure), desc=\"Building exposure JSONs\") if HAS_TQDM else all_exposure.iterrows()\n",
    "\n",
    "for idx, row in iterator:\n",
    "    extraction = row['extraction']\n",
    "    exposure_block = build_exposure_block(extraction, row['id'])\n",
    "\n",
    "    if exposure_block:\n",
    "        rdls_record = {\n",
    "            'datasets': [{\n",
    "                'id': f\"rdls_exp-hdx_{row['id'][:8]}\",\n",
    "                'title': row['title'],\n",
    "                'risk_data_type': ['exposure'],\n",
    "                'exposure': exposure_block,\n",
    "                'links': [{\n",
    "                    'href': 'https://docs.riskdatalibrary.org/en/0__3__0/rdls_schema.json',\n",
    "                    'rel': 'describedby'\n",
    "                }]\n",
    "            }]\n",
    "        }\n",
    "\n",
    "        output_path = OUTPUT_DIR / f\"rdls_exp-hdx_{row['id'][:8]}.json\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(rdls_record, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        generated += 1\n",
    "    else:\n",
    "        skipped += 1\n",
    "\n",
    "print(f\"\\nDone.\")\n",
    "print(f\"  Generated: {generated:,} exposure block JSONs\")\n",
    "print(f\"  Skipped (no valid block): {skipped:,}\")\n",
    "print(f\"  Output: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Notebook completed: 2026-02-10T09:20:21.230865\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nNotebook completed: {datetime.now().isoformat()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
