{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "067cb34f",
   "metadata": {},
   "source": [
    "# 08 â€” OSM pilot track (controlled)\n",
    "\n",
    "This notebook prepares a **small, curated whitelist** for OSM-related datasets/products, so you can test conversion without flooding the RDLS output.\n",
    "\n",
    "**Outputs**\n",
    "- `rdls/pilot/osm_whitelist_dataset_ids.txt`\n",
    "- `rdls/docs/osm_pilot_protocol.md`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f70560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# Config (edit if needed)\n",
    "# ======================\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "DUMP_DIR = Path(\"../hdx_dataset_metadata_dump\").resolve()\n",
    "RDLS_DIR = DUMP_DIR / \"rdls\"\n",
    "\n",
    "# Input from earlier steps (adjust names if needed)\n",
    "OSM_EXCLUSION_REPORT = RDLS_DIR / \"reports\" / \"osm_exclusion_report.csv\"   # optional\n",
    "STEP5_REVIEW_PACK = RDLS_DIR / \"reports\" / \"review_pack.csv\"             # optional (if you export it here)\n",
    "\n",
    "PILOT_DIR = RDLS_DIR / \"pilot\"\n",
    "DOCS_DIR = RDLS_DIR / \"docs\"\n",
    "PILOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DOCS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUT_WHITELIST = PILOT_DIR / \"osm_whitelist_dataset_ids.txt\"\n",
    "OUT_PROTOCOL = DOCS_DIR / \"osm_pilot_protocol.md\"\n",
    "\n",
    "TARGET_N = 20  # size of pilot\n",
    "\n",
    "print(\"DUMP_DIR:\", DUMP_DIR)\n",
    "print(\"OUT_WHITELIST:\", OUT_WHITELIST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb3093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# Build a pilot shortlist (best-effort)\n",
    "# ======================\n",
    "import random\n",
    "\n",
    "candidates = []\n",
    "\n",
    "if STEP5_REVIEW_PACK.exists():\n",
    "    df = pd.read_csv(STEP5_REVIEW_PACK)\n",
    "    # Heuristic: prefer OSM-tagged candidates that are NOT excluded by policy\n",
    "    cols = set(df.columns)\n",
    "    if {\"dataset_id\", \"rdls_candidate\"}.issubset(cols):\n",
    "        sub = df[df[\"rdls_candidate\"] == True].copy()\n",
    "        # If you have explicit OSM flag/label, filter further; otherwise keep as is.\n",
    "        candidates = sub[\"dataset_id\"].astype(str).dropna().tolist()\n",
    "\n",
    "elif OSM_EXCLUSION_REPORT.exists():\n",
    "    df = pd.read_csv(OSM_EXCLUSION_REPORT)\n",
    "    if \"dataset_id\" in df.columns:\n",
    "        candidates = df[\"dataset_id\"].astype(str).dropna().tolist()\n",
    "\n",
    "# Fallback: empty -> stop early\n",
    "if not candidates:\n",
    "    print(\"No candidate list found. Provide STEP5_REVIEW_PACK or OSM_EXCLUSION_REPORT.\")\n",
    "else:\n",
    "    # Deduplicate and sample\n",
    "    candidates = sorted(set(candidates))\n",
    "    if len(candidates) > TARGET_N:\n",
    "        random.seed(42)\n",
    "        pick = random.sample(candidates, TARGET_N)\n",
    "    else:\n",
    "        pick = candidates\n",
    "\n",
    "    OUT_WHITELIST.write_text(\"\\n\".join(pick) + \"\\n\", encoding=\"utf-8\")\n",
    "    print(\"Wrote whitelist IDs:\", len(pick))\n",
    "    print(\"First 10:\", pick[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc3114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# Write a simple pilot protocol (Markdown)\n",
    "# ======================\n",
    "protocol = f\"\"\"# OSM Pilot Protocol\n",
    "\n",
    "## Purpose\n",
    "Test the RDLS translation pipeline on a **small controlled set** of OSM-related datasets/products.\n",
    "\n",
    "## Inputs\n",
    "- Whitelist: `{OUT_WHITELIST}`\n",
    "- RDLS schema: `rdls/schema/rdls_schema_v0.3.json`\n",
    "\n",
    "## Pilot principles\n",
    "1. Generate RDLS metadata only for the curated whitelist (or, preferably, for your own derived OSM products).\n",
    "2. Deduplicate by (ISO3, theme, date) if multiple HDX datasets represent the same logical product.\n",
    "3. No override-includes for datasets that are excluded by policy, unless explicitly agreed.\n",
    "\n",
    "## How to use\n",
    "1. Run Step 06 with an argument/flag to restrict to the whitelist IDs.\n",
    "2. Validate outputs (Step 07).\n",
    "3. Review the outputs manually; iterate mapping rules only after you agree on policy.\n",
    "\n",
    "\"\"\"\n",
    "OUT_PROTOCOL.write_text(protocol, encoding=\"utf-8\")\n",
    "print(\"Wrote:\", OUT_PROTOCOL)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
